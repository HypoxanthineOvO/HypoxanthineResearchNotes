```table-of-contents
```
# 1. Abstract
Neural Radiance Fields (NeRF) 在 Novel View Synthesis 方面取得了巨大成功。然而，由于潜在的校准信息不完美和场景表示不准确，现有的基于 NeRF 的方法在从真实场景中恢复高质量细节方面仍然具有挑战性。即使使用高质量的训练帧，NeRF 模型生成的合成新视图仍然存在明显的渲染伪影，如噪声和模糊。为了解决这个问题，我们提出了 NeRFLiX，一种通用的 NeRF 无关的修复范式，它学习了一种退化驱动的跨视角混合器。特别地，我们设计了一种 NeRF 风格的退化建模方法，并构建了大规模的训练数据，使得深度神经网络能够有效去除 NeRF 原生的渲染伪影。此外，除了退化去除，我们还提出了一种跨视角聚合框架，融合了高度相关的高质量训练图像，将最先进的 NeRF 模型性能推向了全新的高度，并生成了高度逼真的合成视图。基于这一范式，我们进一步提出了 NeRFLiX++，它具有更强的两阶段 NeRF 退化模拟器和更快的跨视角混合器，显著提高了计算效率，并实现了卓越的性能。值得注意的是，NeRFLiX++ 能够从噪声低分辨率的 NeRF 渲染视图中恢复出逼真的超高分辨率输出。大量实验证明了 NeRFLiX++ 在各种 Novel View Synthesis 基准上的优秀修复能力。
# 2. Introduction
逼真的 Novel View Synthesis 是计算机视觉和图形学领域长期存在的问题。近年来，基于学习的方法如 NeRF (Neural Radiance Fields) 及其后续工作涌现出来，它们利用神经网络表示 3D 场景，并采用各种渲染技术来合成新视图。为了实现高质量的渲染，设计物理感知系统至关重要，该系统需要优化多个因素，包括几何、环境光照、物体材质和相机姿态。然而，尽管取得了进展，最先进的 NeRF 模型在仅依赖有限数量的输入视图时，仍然可能产生不理想的渲染伪影，如 [20], [24], [34], [64], [82], [83] 中讨论的那样。
为了实现高质量的 Novel View Synthesis，我们提出了 NeRFLiX [86]，它首次探索了模拟大规模 NeRF 风格配对数据的可行性，以训练一个 NeRF 无关的修复器。该系统由两个主要组件组成：
1. NeRF 风格的退化模拟器 (NDS) 
2. 跨视角混合器 (IVM)
受实际图像修复方法 [58], [77] 的启发，**NeRFLiX 系统分析了典型的 NeRF 渲染伪影，并提出了三种手动设计的退化来模拟 NeRF 渲染的噪声**。我们利用 NDS 生成大量模拟训练数据，并进一步开发了一个深度修复器，即 IVM，以去除 NeRF 风格的伪影。因此，NeRFLiX 在合成高保真度的新视图方面表现出色，从而将 NeRF 模型的能力扩展到了新的前沿。然而，有两个方面值得进一步研究：
1. 手动设计的退化在考虑真实 NeRF 渲染伪影的分散性方面存在不足
2. 在处理高分辨率帧时，使用大型跨视角混合器的难度较大
此后，我们通过引入两阶段退化模拟方法和更高效的引导跨视角混合器，将 NeRFLiX 扩展为 NeRFLiX++。这一改进的框架不仅实现了卓越或相当的性能，还显著提高了推理效率。
**两阶段退化模拟**：为了缩小 NeRF 渲染伪影与模拟伪影之间的领域差距，我们提出了一种两阶段退化模拟方案，该方案由手工设计的退化模拟器和深度生成退化模拟器组成。在第一阶段，我们使用与 NeRFLiX 类似的退化流程，但加入了更多的基本退化（即光照喷射和亮度压缩）以获得初始退化帧。在第二阶段，我们利用生成对抗训练来优化第一阶段的输出，使其在统计上更接近 NeRF 渲染的视图。然而，由于目标域中的样本有限，训练深度生成网络具有挑战性。我们观察到，传统的像素到像素监督实际上限制了模拟噪声的多样性。为了解决这个问题，我们借鉴了 BebyGAN [30] 的灵感，提出了一种利用图像自相似性并引入加权 top-K buddy 损失进行对抗训练的新方法。具体来说，给定一个模拟的 patch，我们从真实样本（NeRF 渲染的图像）中搜索 K 个最相关的“伙伴”（图像 patch），然后使用它们提供弱监督。这种方法显著增强了生成模式的多样性，从而改进了退化建模。通过两阶段模拟器，我们能够构建大量的训练对，并证明各种深度修复器可以通过模拟样本有效消除 NeRF 风格的伪影。
**引导跨视角混合器**：为了克服 NeRFLiX 在处理高分辨率帧时的效率挑战，我们提出了一种更高效的引导跨视角聚合方案。我们首先在低分辨率下估计密集的像素级对应关系（光流），基于几个考虑。首先，下采样操作导致图像之间的位移较小，从而降低了估计的难度。其次，渲染视图和参考视图的分布变得更接近，从而实现了更准确的对应关系估计。最后，这种方法在计算上更高效。然后，我们通过利用在较低尺度上预测的运动场来聚合较高尺度的信息，实现了从粗到细的引导聚合。这种策略消除了对高分辨率对应关系估计的重复需求，大大提高了计算效率。与 NeRFLiX 相比，NeRFLiX++ 在基准数据集（如 Tanks and Temples 和 Noisy LLFF Synthetic）上取得了更好的结果，同时在 LLFF 数据集上表现相当。值得注意的是，NeRFLiX++ 在处理 1024×1024 大小的场景时速度提高了 9.2 倍，突显了其显著的效率提升。
总结来说，我们的贡献有三点：
- **准确的 NeRF 退化建模**：我们提出了一种两阶段退化建模方案，该方案紧密逼近了真实 NeRF 渲染伪影的统计特性。通过这一方案，我们证明了现有深度图像/视频修复器以及我们提出的 NeRFLiX/NeRFLiX++ 在使用模拟样本进一步提升 NeRF 渲染视图质量方面的有效性。
- **高效的跨视角混合器**：我们开发了一种高效的跨视角聚合方法，有效地整合了来自多个视角的信息，实现了对超高分辨率帧的快速准确处理。
- **高质量的超分辨率**：鉴于我们加速的跨视角聚合的高效性，我们展示了 NeRFLiX++ 在超分辨率任务中的潜力，能够从噪声的 1 K NeRF 渲染视图中生成逼真的 4 K 帧，如图 1 所示。
我们工作的初步版本 NeRFLiX [86] 已被 IEEE/CVF 计算机视觉会议 (CVPR) 2023 接受。这个扩展版本提出了几个关键贡献和进展。首先，我们通过引入一种新颖的两阶段退化方案，解决了手工设计退化的局限性，更好地模拟了 NeRF 渲染帧的复杂分布。其次，我们系统分析了循环跨视角混合器的效率，并提出了一种更快的替代方案。这些改进使得 NeRFLiX++ 在显著降低计算成本的同时，实现了卓越的性能。此外，我们展示了 NeRFLiX++ 可以轻松应用于从低分辨率 NeRF 渲染视图中超分辨出逼真的 4 K 图像，且只需最小的架构修改。NeRFLiX++ 的代码将发布在 https://redrock303.github.io/nerflixplus/ 以促进未来的研究。
# 3. Related Work
在本节中，我们回顾了与 NeRF 相关的 Novel View Synthesis、低版本中的退化模拟以及帧间对应关系估计的相关方法。
## 3.1. 基于 NeRF 的 Novel View Synthesis
这一领域最近受到了广泛关注，并得到了深入研究。Mildenhall 等人 [40] 首次提出了神经辐射场，通过隐式表示静态 3D 场景并从多个姿态图像中合成新视图。受其成功的启发，许多基于 NeRF 的模型 [2], [10], [12], [14], [20], [21], [23], [25], [27], [35], [37], [38], [41], [43], [45], [47], [50], [54], [56], [65], [69], [78], [81] 被提出。例如，Point-NeRF [67] 和 DS-NeRF [15] 结合了稀疏 3D 点云和深度信息，以消除 NeRF 的几何模糊性，实现了更准确和高效的 3D 点采样以及更好的渲染质量。Plenoxels [17], TensoRF [9], DirectVoxGo [48], Fast-NeRF [18], Plenoctrees [72], KiloNeRF [46] 和 Mobilenerf [11] 旨在使用各种先进技术来加速训练或推理阶段。尽管这些方法取得了很大进展，但由于相机姿态不准确、简化的针孔相机模型以及场景表示不准确等潜在问题，它们在预测新视图时仍然存在渲染伪影。
## 3.2. 退化模拟
由于目前没有尝试探索 NeRF 风格的退化，我们概述了与我们的工作最相关的真实世界图像修复工作。以前的图像和视频超分辨率方法 [16], [29], [30], [33], [57], [59], [73], [84], [84], [85] 通常遵循固定的图像退化类型（例如模糊、双三次或双线性下采样）。由于真实世界和模拟退化之间的领域差距较大，早期的图像修复方法 [29], [31], [76], [84] 通常无法去除真实世界图像的复杂伪影。相比之下，BSRGAN [77] 设计了一种实用的退化方法，用于真实世界图像的超分辨率。在其退化过程中，考虑了多种退化并以随机顺序应用，大大覆盖了真实世界退化的多样性。与之前的工作相比，BSRGAN 在定量和定性上都取得了更好的结果。Real-ESRGAN [58] 开发了二阶退化过程，用于真实世界图像的超分辨率。与专注于消除图像和视频压缩、运动模糊、视频隔行扫描和传感器噪声的真实世界图像和视频处理系统不同，NeRF 渲染涉及不同的退化模式。据我们所知，我们是第一个研究 NeRF 风格退化去除的。
## 3.3.  对应关系估计
在现有文献中，视频修复方法 [3], [7], [51], [55], [74] 旨在从多个低质量帧中恢复高质量帧。为了实现这一目标，跨帧对应关系估计对于有效聚合信息的时间内容至关重要。一些工作 [6], [7], [68], [74] 通过光流估计建立像素级对应关系，并执行帧扭曲以实现多帧补偿。另一类工作 [52], [57], [85] 尝试使用可变形卷积网络 (DCNs [13]) 进行自适应对应关系估计和聚合。最近，基于 transformer 的视频修复模型 [5], [32] 通过注意力机制实现时空聚合，并取得了有希望的性能。然而，在具有非常不同视角的帧之间执行准确的对应关系估计仍然具有挑战性。
## 3 .4. 高分辨率 NeRF (HR-NeRFs)
为了提高高分辨率渲染的视觉质量，开发了各种 NeRF 技术 [22], [54], [61], [71]。NeRF-SR [54] 采用两阶段训练过程，首先使用超采样从低分辨率视图中生成高分辨率输出，然后通过整合参考 patch 的信息来细化它。4 K-NeRF [61] 采用了类似的方法，利用 DVGO [48] 近似 3D 场景表示，并使用视图一致的编码器-解码器进行高质量渲染。Ref-SR NeRF [22] 优化了低分辨率 NeRF 表示，并整合了基于参考的超分辨率模型以构建高分辨率视图。CROP-NeRF [71] 采用交叉优化方案，通过同时优化深度图像超分辨率模型来改进 NeRF 表示。
相比之下，我们的 NeRFLiX/NeRFLiX++ 具有场景无关的训练和成本效益的重新配置优势。首先，我们的方法与现有方法不同，现有方法需要多阶段的场景特定训练，而我们采用单一训练过程。直接应用于新场景大大减少了训练开销。其次，在传统的 HR-NeRF 中，初始 NeRF 模型和细化模型的联合优化使它们紧密耦合，如果任一组件被替换，可能会导致性能下降。相反，我们的框架有效地解耦了 NeRF 渲染和细化阶段，增强了对现有或未来 NeRF 的适应性。表 10 b 和表 1 的结果清楚地展示了 NeRFLiX++ 实现的显著改进、强大的泛化能力和提高的计算效率。
# 4. Preliminaries
在本节中，我们回顾了基于 NeRF 的 Novel View Synthesis 的一般流程，并讨论了潜在的渲染伪影。如图 2 所示，渲染过程涉及三个主要步骤：(1) 光线投射，(2) 光线行进，和 (3) 辐射累积。
- **Ray Casting**：为了渲染特定视图中目标像素的颜色，NeRF 利用相机的校准参数 π 生成一条光线 r (o, d) 通过该像素，其中 o 和 d 分别是相机中心和光线方向。
- **Ray Marching*：沿着选定的光线在 3D 场景中采样一组 3D 点，这些点由神经辐射场表示。NeRF 编码 3D 场景并预测这些点的颜色和密度。
- **Volume Rendering**：通过积分采样的 3D 点的预测辐射特征来提取像素颜色。
**讨论**：我们看到，建立 2D 照片与相应 3D 场景之间的关系需要相机校准。不幸的是，精确校准相机姿态非常具有挑战性，导致 3D 采样噪声。同时，一些先前的工作 [24], [62], [70], [75] 也提出了其他问题，包括非线性针孔相机模型 [24] 和形状-辐射模糊性 [79]。由于这些固有的局限性，如第 1 节所讨论的，NeRF 模型可能会合成不理想的新测试视图。

# 5. NeRFLiX

在这项工作中，我们提出了 NeRFLiX，一种通用的 NeRF 无关的修复器，它采用退化驱动的跨视角混合器来增强由 NeRF 模型渲染的新视图图像。它由两个基本组件组成：NeRF 风格的退化模拟器 (NDS) 和跨视角混合器 (IVM)。如图 4 a 所示，在训练阶段，我们使用提出的 NDS 创建大规模配对训练数据，随后用于训练 IVM，以利用两个参考图像（参考视图）改进 NeRF 渲染的视图。在推理阶段，如图 4 b 所示，IVM 被用于通过融合来自选定的最相关参考视图的有用信息来增强渲染视图。

## 5.1 NeRF-Style Degradation Simulator (NDS)
由于在各种环境下收集良好姿态的场景并训练 NeRF 模型的困难，直接收集大量配对的 NeRF 数据以去除伪影是不可行的。为了解决这一挑战，受 BSRGAN [77] 的启发，我们设计了一种通用的 NeRF 退化模拟器，以生成视觉和统计上与 NeRF 渲染图像（视图）相当的大规模训练数据集。首先，我们从 LLFF-T 和 Vimeo 90 K [68] 收集原始数据，其中相邻帧被视为原始序列。每个原始序列由三张图像 {I_gt, I_{r_1}, I_{r_2}} 组成：一个目标视图 I_gt 和它的两个参考视图 {I_{r_1}, I_{r_2}}。为了从原始序列构建配对数据，我们使用提出的 NDS 对 I_gt 进行退化，并获得模拟视图 I，如图 4 (a) 所示。
退化流程如图 3 所示。我们设计了三种类型的退化来处理目标视图 I_gt：splatted Gaussian noise (SGN)、re-positioning (Re-Pos.) 和 anisotropic blur (A-Blur)。需要注意的是，可能存在其他模型用于这种模拟，我们仅使用此路径来评估和证明我们想法的可行性。
**Splatted Gaussian noise**：尽管加性高斯噪声经常用于图像和视频去噪，但 NeRF 渲染噪声明显不同。由于相机参数噪声，击中 3D 点的光线将在附近的 2D 区域内重新投影。因此，NeRF 风格的噪声分散在 2D 空间中。这一观察促使我们提出了 splatted Gaussian noise，其定义为：
$$ I_{D1} = (I_{gt} + n) \circledast g $$
其中 $n$ 是与 $I_gt$ 分辨率相同的 2D 高斯噪声图，$g$ 是各向同性高斯模糊核。
**Re-positioning**：我们设计了一种 re-positioning 退化来模拟光线抖动。我们为位置 $(i, j)$ 的像素添加一个随机的 2D 偏移 $δ_i, δ_j ∈ [−2,2]$，概率为 $0.1$：
$$ I_{D2}(i,j) = \begin{cases} 
I_{D1}(i,j) & \text{if } p > 0.1 \\
I_{D1}(i + \delta_i, j + \delta_j) & \text{else } p \leq 0.1 
\end{cases} $$
其中 p 在 [0,1] 上均匀分布。
**Anisotropic blur**：从我们的观察中，NeRF 合成帧也包含模糊内容。为了模拟模糊模式，我们使用各向异性高斯核对目标帧进行模糊处理。神经辐射场通常由不平衡的训练视图监督。因此，给定一个新视图，投影的 2D 区域具有不同的退化水平。因此，我们以空间变化的方式执行每种退化。更具体地，我们定义一个掩码 M 为一个二维定向各向异性高斯 [19]，如：
$$ M(i,j) = G(i - c_i, j - c_j; \sigma_i, \sigma_j, A) $$
其中 $(c_i, c_j)$ 和 $(σ_i, σ_j)$ 是均值和标准差，A 是定向角度。之后，我们使用掩码 $M$ 线性混合每种退化的输入和输出，最终实现区域自适应退化。
最后，通过我们的 NDS，我们可以获得大量的训练对，每个配对数据由两个高质量参考视图 $\{I_{r_1}, I_{r_2}\}$、一个模拟退化视图 I 和相应的目标视图 I_gt 组成。接下来，我们展示了如何利用构建的配对数据 $\{I, I_{r_1}, I_{r_2} | I_gt\}$ 来训练我们的 IVM。

## 5.2 Inter-viewpoint Mixer (IVM)
**问题公式化**：给定由我们的 NDS 或 NeRF 模型生成的退化视图 I，我们的目标是从其两个高质量参考视图 $\{I_{r_1}, I_{r_2}\}$ 中提取有用信息，并恢复增强版本 $\hat{I}$。
**IVM 架构**：对于多帧处理，现有技术要么使用光流 [6], [55], [74]，要么使用可变形卷积 [13], [32], [57] 来实现对应关系估计和一致位移的聚合。相比之下，NeRF 渲染和输入视图可能来自非常不同的角度和位置，这使得精确聚合具有挑战性。
为了解决这个问题，我们提出了 IVM，一种混合循环跨视角“混合器”，它逐步从两个高质量参考视图中融合像素级和 patch 级内容，从而实现更有效的跨视角聚合。IVM 包含三个模块：特征提取、混合跨视角聚合和重建，如图 5 所示。
**特征提取**：在特征提取阶段，我们使用两个卷积编码器分别处理退化视图 I 和两个高质量参考视图 $\{I_{r_1}, I_{r_2}\}$。然后，我们使用跨视角窗口注意力模块和可变形卷积来实现循环的 patch 级和像素级聚合。最后，增强视图 $\hat{I}$ 通过重建模块生成，并在监督下进行优化：
$$ \text{Loss} = |\hat{I} - I_{gt}|, \quad \text{其中} \quad \hat{I} = f(I, I_r1, I_r2; \theta) $$
其中 $\theta$ 是 IVM 的可学习参数。架构细节在我们的补充材料中提供。
**视图选择**：在推理阶段，对于 NeRF 渲染的视图 I，我们的 IVM 通过聚合来自两个相邻高质量视图的内容来生成增强版本。尽管提供了多个高质量视图（用于训练），但只有其中一部分与 I 有较大重叠。我们仅采用对跨视角聚合最有用的最相关视图。
为此，我们开发了一种视图选择策略，从输入视图中选择两个与渲染视图 I 重叠最多的参考视图 $\{I_{r_1}, I_{r_2}\}$。具体来说，我们基于针孔相机模型来制定视图选择问题。如图 6 所示，任意 3D 场景可以近似为一个包围球，相机围绕它拍摄照片。当相机发射的光线击中球体时，会有一组交点。我们将 3D 点集表示为 $\Phi_i = \{p_i^0, p_i^1, \dots, p_i^{M_i}\}$ 和 $\Phi_j = \{p_j^0, p_j^1, \dots, p_j^{M_j}\}$，分别对应第 i 和第 j 个相机。对于视图 i 的第 m_i 个交点 $p_i^{m_i} \in \Phi_i$，我们搜索其在视图 j 中的最近点，使用 L 2 距离：
$$ p_i^{m_i \to j} = \arg \min_{p \in \Phi_j} (||p - p_i^{m_i}||_2^2) $$
然后，从第 i 个视图到第 j 个视图的匹配成本计算为：
$$ C_{i \to j} = \sum_{m_i=0}^{M_i} ||p_i^{m_i} - p_i^{m_i \to j}||_2^2 $$
我们最终得到视图 i 和 j 之间的相互匹配成本：
$$ C_{i \leftrightarrow j} = C_{i \to j} + C_{j \to i} $$
因此，选择两个参考视图 {I_{r_1}, I_{r_2}} 时，选择具有最小相互匹配成本的视图来增强 NeRF 渲染的视图 I。需要注意的是，我们在训练阶段也采用此策略来决定 LLFF-T [39] 数据的两个参考视图。

# 6. NeRFLiX++
基于 NeRFLiX，我们提出了 NeRFLiX++，它具有两阶段退化建模策略和引导跨视角混合器，以进一步提高修复性能和效率。
## 6.1 Two-stage Degradation Modeling
我们提出的两阶段退化建模方法包括手工设计的退化模拟器和深度生成退化模拟器，如图 7 所示。在第一阶段，我们使用多种手工设计的退化从选定的干净视图中生成初始退化帧，灵感来自 NeRFLiX。在第二阶段，深度生成退化模拟器用于细化第一阶段的结果，并生成最终的模拟视图。
**手工退化模拟器**：除了 NeRFLiX 中使用的三种基本退化（splatted Gaussian noise、re-positioning 和各向异性高斯模糊），我们引入了两种额外的退化模式以增强模拟的真实性。我们对这两种额外的退化应用与 NeRFLiX 相同的区域自适应退化策略。
**光照喷射**：为了考虑由视角依赖的着色引起的光照变化，我们提出了对目标视图和参考视图进行 gamma 调整。调整定义为：
$$ y = \text{power}(x, \gamma) $$
其中 “power” 表示指数函数，$\gamma$ 是从 [0.95, 1.05] 随机采样的线性调整常数。
**亮度压缩**：为了模拟 NeRF 渲染中可能出现的结构缺陷，我们提出了一种图像压缩过程，该过程会降低目标帧的灰度密度。具体来说，我们首先将 RGB 帧转换为 LAB 色彩空间，并使用 JPEG 算法在随机选择的压缩级别（20% 到 90%）下压缩 L 分量。然后，我们将退化的 L 通道与原始 AB 通道合并，并将其转换回 RGB 色彩空间。
**深度生成退化模拟器**：如第 1 节所述，手工设计的退化可能无法捕捉到实际 NeRF 风格伪影的全部范围。为了解决这一限制，我们提出了一种深度生成退化模拟器，该模拟器细化手工退化阶段的结果，并缩小模拟域和目标域之间的差距。
生成对抗网络 (GANs) 在图像到图像翻译任务中表现出色，前提是有大量训练样本可用。然而，NeRF 渲染帧的可用数据稀缺，这给使用 GANs 直接拟合底层退化分布带来了重大挑战。为了解决这个问题，受 BebyGAN [30] 的启发，我们提出了一种加权 top-K 相似性损失（WKS），作为辅助损失函数来帮助对抗训练。如图 7 所示，我们使用 UNet 处理第一阶段的退化视图 $I_{S1}$，以获得细化结果 $I_{S2}$。除了传统的对抗和重建损失外，我们还利用 WKS 生成具有更多多样性的结果 $I_{S2}$。
**WKS**：图 8 展示了加权 top-K 监督。给定 $I_{S2}$ 的第 i 个 patch，记为 $g_{S2}^i$，我们使用三重距离函数从相应的真实渲染视图 I 中搜索 top-K 相似 patch $g_{i,\{1,2,\dots,K\}}^*$。三重距离函数定义为：
$$ g_{i,\{1,2,\dots,K\}}^* = \text{topK}_{g \in G} \left( \alpha ||g - g_{S2}^i||_2^2 + \beta ||g - g_{gt}^i||_2^2 \right) $$
其中 $g_{gt}^i$ 是对应的真实渲染 patch，G 是通过展开真实渲染视图 I 生成的候选 patch 集，$\alpha$ 和 $\beta$ 是两个缩放因子，用于平衡两个距离项。根据 BebyGAN [30] 的经验实验，我们将它们设置为 1 以获得更好的评估结果。在获得 top-K 相似 patch 后，提出的 WKS 公式为：
$$ L_{\text{TopK}} = \sum_{k=1}^K ||(g_{i,k}^* - g_{S2}^i) * w_{i,k}||_1 $$
其中 $w_{i,k}$ 是第 k 个归一化权重，计算为：
$$ d_{i,k} = -\frac{1}{2} ||g_{i,k}^* - g_{S2}^i||_2^2, \quad w_{i,k} = \frac{\exp(d_{i,k})}{\sum_{m=1}^K \exp(d_{i,m})} $$
$d_{i,k}$ 是预测 patch $g_{S2}^i$ 与其第 k 个最相似 patch 之间的缩放负 L 2 距离。
**讨论**：我们提出的加权 top-K 相似性损失采用动态策略从真实渲染帧中搜索多个相关 patch，丰富了监督信号的多样性。这种方法鼓励模型找到比预定义标签更接近退化程度的高度相似目标 patch，从而实现了更准确和有效的训练。在我们的实验中，我们证明了这种设计的有效性，并表明它在 NeRF 渲染帧数据有限的情况下显著提高了 GANs 的性能。
## 6.2 Guided Inter-viewpoint Mixer
在典型的 NeRF 设置中，高质量输入视图是免费的，它们可以作为渲染视图修复的潜在参考基础。为了实现跨视角混合，NeRFLiX 提出了一种循环聚合模型来处理不同的视角变化。然而，如第 1 节所述，由于计算开销大，处理高分辨率帧仍然不切实际。
为了克服这一限制，我们提出了一种引导跨视角混合器（称为“G-IVM”），它具有高效的多视图融合模块。图 9 展示了 G-IVM 的框架架构。我们的方法首先利用现成的光流模型在低分辨率下预测渲染视图 I 与其参考视图 {I_1, I_2} 之间的粗略对应关系。基于粗略预测作为引导，我们提出了一种金字塔神经网络来进行从粗到细的聚合。
我们的引导跨视角混合器是 NeRFLiX [86] 中 IVM 方法的扩展，包含三个完整模块：特征提取、引导跨视角聚合和金字塔重建。
**粗略对应关系估计**：为了建立给定输入视图 I 与其参考视图 {I_1, I_2} 之间的粗略对应关系，我们使用预训练的 SPyNet [44] 模型在 1/4 下采样尺度下预测光流 $C_{1/4}^{\{1,2\}}$。
**特征提取**：我们引入了两个卷积编码器，称为“Encoder-1/2”，分别从渲染视图 I 和其两个参考视图 $I_{1,2}$ 中提取深度金字塔图像特征 $F_{\{1/8, 1/4, 1/2\}}$ 和 $F_{\{1/8, 1/4, 1/2\}}^{\{1,2\}}$。具体来说，通过应用三个步长为 2 的卷积，金字塔特征在 1/8、1/4 和 1/2 尺度上。
**引导跨视角聚合**：考虑到准确估计渲染视图 I 与其参考视图 {I_1, I_2} 之间的大位移的困难，我们提出了一种引导跨视角聚合方法，该方法以从粗到细的方式操作。我们的方法采用流引导的可变形卷积 (FDCN) 技术，利用 SPyNet 计算的光流来促进 $F_{1/8}$ 及其对应参考视图 $F_{1/8}^1, F_{1/8}^2$ 的聚合。该过程公式化为：
$$ C_{1/8}^i = \frac{1}{2} \text{Bilinear}(C_{1/4}^i, \frac{1}{2}), \quad M_{1/8}^i = [F_{1/8}, F_{1/8}^i, C_{1/8}^i], \quad \hat{F}_{1/8}^i = \text{FDCN}(F_{1/8}^i, M_{1/8}^i, C_{1/8}^i) $$
其中 $i \in \{1,2\}$ 是参考索引，Bilinear (·, s) 是双线性插值函数（s 是缩放因子），$M_{1/8}^i$ 是偏移特征，$\hat{F}_{1/8}^i$ 表示从第 i 个参考视图到目标图像的对齐特征。在获得两个聚合特征 $\hat{F}_{1/8}^{\{1,2\}}$ 后，我们使用 3D 卷积层将它们与目标视图特征 $F_{1/8}$ 融合：
$$ \hat{F}_{1/8} = \text{Conv3D}(\hat{F}_{1/8}^{\{1,2\}}, F_{1/8}) $$
其中 $\hat{F}_{1/8}$ 是融合特征。
接下来，我们继续进行 1/4 尺度的聚合阶段。我们选择 2× 上采样的对应物 $\hat{F}_{1/8}^{\uparrow 2}$ 作为目标视图特征，而不是直接使用特征 $F_{1/4}$。这一选择是因为渲染视图 I 可能存在伪影。由于 $\hat{F}_{1/8}$ 已经聚合了来自参考视图的高质量细节，因此它被认为更适合进行涉及 $F_{1/4}^i$ 和目标视图的对应关系估计：
$$ F_{1/8}^{\uparrow 2} = \text{Bilinear}(\hat{F}_{1/8}, 2), \quad M_{1/4}^i = [F_{1/8}^{\uparrow 2}, F_{1/4}^i, C_{1/4}^i], \quad \hat{F}_{1/4}^i = \text{FDCN}(F_{1/4}^i, M_{1/4}^i, C_{1/4}^i) $$
然后，我们使用另一个 3D 卷积层来混合两个聚合特征 $\hat{F}_{1/4}^{\{1,2\}}$：
$$ \hat{F}_{1/4} = \text{Conv3D}(\hat{F}_{1/4}^{\{1,2\}}, F_{1/4}) $$
最后，我们进行第三级聚合以获得融合特征 $\hat{F}_{1/2}$，使用与第二阶段类似的处理步骤。

**金字塔重建和多尺度监督**：我们利用金字塔聚合特征 $\hat{F}_{\{1/8, 1/4, 1/2\}}$ 生成多尺度输出。首先，从 $\hat{F}_{1/8}$ 开始，我们使用卷积块获得最低尺度的输出 $\hat{I}_{1/8}$。然后，我们上采样此输出并整合 $\hat{F}_{1/4}$ 以学习更高尺度的图像残差，生成 $\hat{I}_{1/4}$。通过遵循此策略，我们最终预测增强视图 $\hat{I}$。为了提高重建质量，我们在训练期间引入多尺度监督：
$$ L_{\{1/8, 1/4\}} = ||\hat{I}_{\{1/8, 1/4\}} - I_{\{1/8, 1/4\}}^{gt}||_1, \quad L_f = ||\hat{I} - I_{gt}||_1, \quad L = 0.1 * L_{\{0,1\}} + L_f $$
其中 $I_{gt}, I_{\{1/8, 1/4\}}^{gt}$ 是全分辨率和下采样后的真实视图。

# 7. Experiment
## 7.1. Implementation Details
首先，我们训练深度生成退化模拟器进行 150 K 次迭代。之后，我们冻结深度生成退化模拟器和 G-IVM 中使用的光流模型的权重，进行接下来的 300 K 次迭代。然后，我们联合训练深度生成退化模拟器和 G-IVM 进行额外的 300 K 次迭代，使用批量大小为 16 和裁剪输入大小为 128×128。我们使用与 NeRFLiX [86] 相同的数据增强技术，并采用 Adam 优化器和余弦退火学习率方案。
## 7.2. Datasets and Metrics
遵循 NeRFLiX，我们在三个流行的数据集上进行实验：LLFF [39]、Tanks and Temples [26] 和 Noisy LLFF Synthetic [40]。前两个基准分别有 8 个和 5 个真实场景。Noisy LLFF Synthetic 有 8 个虚拟场景，我们手动对精确的相机姿态应用相机抖动，以模拟野外校准的不完美。
我们使用 PSNR (↑)、SSIM [60] (↑) 和 LPIPS [80] (↓) 指标评估我们的方法，与 NeRF 模型的评估标准一致。
## 7.3. Improvements over SOTA NeRFs
我们通过在各种数据集上持续改进最先进的 NeRF 模型的性能来验证 NeRFLiX++ 的有效性。此外，我们进行了全面的定量和定性比较，评估 NeRFLiX++ 和 NeRFLiX 的推理效率。
**LLFF**：为了检验 NeRFLiX++ 的增强潜力，我们研究了六个代表性模型，包括 NeRF [40]、TensoRF [9]、Plenoxels [17]、NeRF-mm [62]、NLF [1] 和 RegNeRF [42]。使用 NeRF 方法渲染的视图（及其参考视图）作为我们模型的输入，我们旨在进一步提高合成质量。定量结果如表 2 所示。在两种协议下，NeRFLiX++ 表现出与 NeRFLiX 相当的改进，将 NeRF 模型的性能提升到了前所未有的水平。例如，NeRFLiX++ 在 Plenoxels [17] 数据集上实现了显著的改进，PSNR/SSIM/LPIPS 分别提高了 0.61 dB/0.025/0.054。值得注意的是，NeRFLiX++ 在处理 1024×1024 大小的场景时速度提高了 9.2 倍，突显了其显著的效率提升。

**Tanks and Temples**：与 LLFF 相比，它的相机视角变化较大。因此，即使是最新的先进 NeRF 模型，如 TensoRF [9] 和 DIVeR [63]，也无法合成高质量的结果。如表 3 a 所示，NeRFLiX 和 NeRFLiX++ 在这些模型上都表现出显著的性能提升。特别是，NeRFLiX++ 表现出更强的泛化能力，从而实现了更显著的性能提升。例如，NeRFLiX++ 在 TensoRF [9] 模型上实现了显著的改进，PSNR/SSIM/LPIPS 分别提高了 0.81 dB/0.017/0.035。

**Noisy LLFF Synthetic**：除了上述的野外基准，我们还展示了我们的模型在 noisy LLFF Synthetic 上的增强能力。从表 3 b 中的结果可以看出，我们的 NeRFLiX++ 在两个最先进的 NeRF 模型上实现了显著的改进。

**性能与计算成本的权衡**：我们研究了使用 NeRFLiX 和 NeRFLiX++ 时性能增强与计算开销之间的权衡。图 10 展示了 PSNR、推理时间和内存使用之间的关系。NeRFLiX++ 显著改进了最先进的 NeRF 模型，同时保持了高分辨率输入的可接受处理速度。例如，NeRFLiX++ 将 NeRF 模型提高了 0.75 dB，而推理时间仅增加了 0.77%（处理 1024×1024 帧时为 0.43 秒）。

**定性结果**：图 11 展示了定性评估的示例。结果表明，NeRFLiX++ 有效地恢复了更清晰的图像细节，同时显著减少了渲染图像中的 NeRF 风格伪影，突显了我们方法的有效性。

## 7.4 Training Acceleration for NeRF Models (continued)

在本节中，我们展示了 NeRFLiX (++) 如何使 NeRF 模型在训练时间减少 50% 的情况下仍能产生更好的结果。具体来说，我们利用 NeRFLiX 和 NeRFLiX++ 来改进两个最先进的 NeRF 模型在训练时间减半后的渲染图像。改进后的结果优于完整训练时间的对应模型，如表 3 c 所示。值得注意的是，NeRFLiX 和 NeRFLiX++ 将 Plenoxels [17] 的训练时间从 24 分钟减少到 10 分钟，同时持续提高了渲染图像的质量。

## 7.5 Ablation Study

在本节中，我们在 LLFF [39] 数据集上进行了全面的实验，以分析我们设计的每个部分。我们使用 TensoRF [9] 作为基线。

**数据模拟质量**：为了评估模拟质量，我们测量了真实渲染帧与由不同退化模型生成的模拟帧之间的分布相似性：BSR [77]、NeRFLiX、NeRFLiX++ 中的深度生成退化以及 NeRFLiX++。我们使用 t-SNE [53] 可视化使用 Inception-v 3 [49] 提取的深度图像特征，如图 12 所示。值得注意的是，我们的两阶段模拟器 NeRFLiX++ 生成的模拟数据在统计上最接近真实渲染图像，超越了其他模型。定量分析进一步支持了这一发现，如表 4 和表 5 所示。

此外，我们进行了详细的分析，以评估退化的各个组成部分，即手工模拟器 (H-C.S) 和深度生成模拟器 (D-G.S)。我们训练了八个模型，逐步加入更多的退化策略。表 5 中的结果突出了每个退化组件在实现理想结果中的重要性。值得注意的是，使用生成退化模拟器的模型优于仅依赖手工退化模拟器的模型。

**加权 top-K 相似性损失 (WKS)**：我们评估了我们提出的 WKS 的性能。为了进行比较，我们训练了一个额外的 G-IVM 模型，使用传统的 L 1 损失作为监督。表 6 中的结果表明，该模型的性能显著低于使用我们提出的 WKS 训练的模型。这一结果强调了 WKS 在深度退化训练中的有效性。

此外，我们研究了 WKS 监督中不同数量的相似 patch (K) 的影响。我们训练了四个额外的 G-IVM 模型。如表 6 所示，我们观察到随着相似 patch 数量从 K=1 增加到 K=5，PSNR 值逐渐提高，之后改进趋于饱和。这种行为是预期的，因为相似性较小的图像 patch 对整体性能的贡献较小。

**G-IVM 中的金字塔融合**：为了利用跨视角帧的多尺度上下文信息，我们引入了一种金字塔引导的聚合结构。表 7 a 表明，加入额外的聚合和重建级别持续提高了最终性能。值得注意的是，我们的完整模型 (Model-A) 实现了最高的 PSNR/SSIM 分数。

**G-IVM 中的光流引导**：为了解决高分辨率帧中不同视角变化的问题，我们引入了使用粗略光流来引导聚合过程。为了评估这一策略的重要性，我们训练了一个额外的模型，称为“NG-IVM”，在相同的实验设置下，但不使用光流引导。表 7 b 中的结果清楚地表明，我们的引导跨视角混合器显著优于 NG-IVM 模型，突显了我们设计的有效性。

**G-IVM 中的对齐目标**：在第 l 级融合中，我们偏离了现有方法 [7], [28], [57], [85]，这些方法将 $F_l$ 作为目标特征。相反，除了第一级对齐 (l=0)，我们提出使用先前聚合的特征 $\hat{F}_{l-1}$ (l>0)。为了验证这一设计选择的有效性，我们比较了这两种策略，结果如表 7 c 所示。我们的融合策略在 PSNR、SSIM 和 LPIPS 方面优于现有解决方案，表明我们的设计更适合 NeRF 无关的修复任务。

**对应关系估计大小**：在第 1 节中，我们讨论了在降低分辨率（缩小 4 倍）下进行粗略对应关系估计的潜在优势。在这里，我们展示了在其他尺度（×1, ×2, ×8, ×16）下的比较。表 8 提供了四个 NeRFLiX++ 模型（ $\text{NeRFLiX++}_{×1, ×2, ×8, ×16}$ ）的结果，以及默认设置（称为“$\text{NeRFLiX++}_{×4}$”）。值得注意的是，$\text{NeRFLiX++}_{×4}$ 在 PSNR 和 SSIM 方面取得了最佳结果。值得注意的是，较大的下采样比率（例如 ×16）可能会影响高分辨率聚合的准确引导性能。

此外，我们评估了不同对齐尺度的计算成本。观察到，进行高分辨率光流估计会增加约 350 ms 的额外推理时间。我们的 ×4 模型在性能与效率之间取得了良好的平衡。

# 8. NeRFLiX++ for 4 K Images

除了低分辨率 novel view rendering 中常见的挑战（如伪影和模糊），使用现有 NeRF 模型渲染高分辨率图像（即 4 K 分辨率）对计算资源提出了重大要求。即使使用高度优化的数据结构（如 TensoRF [9] 中的张量分解），在 NVIDIA RTX 3090 上训练 TensoRF 模型以生成 2 K 和 4 K 图像仍然不切实际，因为 GPU 内存的限制。

在本节中，我们研究了利用 NeRFLiX++ 从不同 NeRF 模型生成的低分辨率图像中进行超分辨和增强，从而生成高质量 4 K 结果的潜力。我们首先定义了问题，然后讨论了 G-IVM 模型的修改。随后，我们进行了定量和定性分析，以评估 NeRFLiX++ 在 4 K 图像上的有效性。

## 8.1 Problem Formulation

给定由 NeRF 模型生成的低分辨率 (1 K) 目标帧 I 及其两个 4 K 参考视图 {I_1, I_2}，$\text{NeRFLIX++}_\text{4K}$ 旨在恢复具有逼真细节的 4 K 输出。

## 8.2 Framework

我们提出的 G-IVM 框架如图 9 所示。为了能够恢复 4 K 图像，我们对 G-IVM 框架进行了最小的修改。

**编码器**：为了适应输入帧 I ∈ R^{H×W} 与其参考视图 {I_1, I_2} ∈ R^{4 H×4 W} 之间的分辨率差异，我们引入了以下调整。对于 encoder-1，我们加入了两个步长为 2 的卷积层，从而生成下采样的参考特征 $F_{\{1/4, 1/2, 1\}}^{\{1,2\}} ∈ R^{\{H×W, 2H×2W, 4H×4W\}}$。Encoder-2 不涉及任何下采样。因此，两个最低分辨率的参考特征 $F_{1/4}^{\{1,2\}} ∈ R^{H×W}$ 与输入特征 $F ∈ R^{H×W}$ 的空间分辨率匹配。

我们训练了两个 $\text{NeRFLIX++}_\text{4K}$ 模型，一个使用 L 1 损失 ($\text{NeRFLIX++}_\text{4K-L1}$)，另一个使用 L 1 和 GAN 损失的组合 ($\text{NeRFLIX++}_\text{4K-GAN}$)。

**实现细节**：与原始 NeRFLiX++ 相比，当使用 1 K 渲染帧作为输入时，我们将两个 1 K 参考帧替换为其 4 K 对应物（从 LLFF-T 获得），同时保持其他训练细节不变。

对于从 Vimeo 数据集中获取的样本，我们首先将输入帧下采样 4 倍，从而建立与 LLFF-T 相同的设置。换句话说，这种配置涉及一个低分辨率输入视图和两个高分辨率参考视图。

## 8.3 Improvements over NeRFs for 4 K Images

为了评估 $\text{NeRFLIX++}_\text{4K}$ 的有效性，我们使用不同的修复方法 (M 1-M 5) 从三个最先进的 NeRF 模型（TensoRF [9]、Plenoxels [17] 和 DVGO [48]）生成的低分辨率输入中生成 4 K 图像。表 9 中的结果表明，所有涉及 NeRFLiX 和 NeRFLiX++ (M 2-M 5) 的模型都优于简单的双三次上采样 (M 1)，表明 NeRFLiX 和 NeRFLiX++ 的修复能力。特别是，$\text{NeRFLIX++}_\text{4K-L1}$ (M 4) 和 $\text{NeRFLIX++}_\text{4K-GAN}$ (M 5) 在 PSNR、SSIM 和 LPIPS 方面取得了最佳性能。此外，图 13 直观地展示了 $\text{NeRFLIX++}_\text{4K-L1}$ (M 4) 生成了具有更清晰纹理和减少渲染伪影的高质量 4 K 帧。同时，$\text{NeRFLIX++}_\text{4K-GAN}$ (M 5) 生成了更多高频细节和更锐利的边缘，从而产生了视觉上更吸引人的结果。

**与 4 K-NeRF 的比较**：我们还将 $\text{NeRFLIX++}_\text{4K}$ 与 4 K-NeRF [61] 进行了比较。表 10 a 中的结果表明，$\text{NeRFLIX++}_\text{4K-L1}$ 在 PSNR 上比 4 K-NeRF_{L 1} 显著提高了 0.77 dB。此外，$\text{NeRFLIX++}_\text{4K-GAN}$ 在感知质量上优于 4 K-NeRF。图 14 直观地展示了 4 K-NeRF_{GAN} 未能重建细微的图像结构，而 $\text{NeRFLIX++}_\text{4K-GAN}$ 有效地从噪声 1 K 照片中恢复了自然图像内容，从而实现了卓越的视觉增强效果。

**与 NeRF-SR 的比较**：我们还将 $\text{NeRFLIX++}_\text{4K-L1}$ 与 NeRF-SR [54] 进行了比较。NeRF-SR 是一种两阶段 Novel View Synthesis 方法。在第一阶段，他们提出了一种超采样 NeRF 模型，从低分辨率训练照片中生成超分辨的新视图。然后，他们使用细化模块来增强第一阶段的结果。为了确保公平比较，我们使用我们的 $\text{NeRFLIX++}_\text{4K-L1}$ 模型来增强他们的第一阶段结果，并与他们的细化结果进行定量比较。表 10 b 表明，$\text{NeRFLIX++}_\text{4K-L1}$ 显著优于 NeRF-SR，突显了我们方法的有效性。

除了其卓越的性能外，与需要为新场景重新训练的 4 K-NeRF 和 NeRF-SR 模型不同，$\text{NeRFLIX++}_\text{4K}$ 具有 NeRF 无关和场景无关的优势。这一特性使得 $\text{NeRFLIX++}_\text{4K}$ 在各种场景中能够快速高效地部署。

**与现有图像和视频修复器的比较**：此外，我们将我们的 $\text{NeRFLIX++}_\text{4K}$ 模型与最先进的图像和视频超分辨率方法（如 SwinIR [33]、RealESRGAN [58] 和 RealBasicVSR [8]）进行了比较。使用 TensoRF [9] 作为基线，我们利用这些模型生成增强的高分辨率图像，并在表 11 中展示了详细结果。尽管这些模型在一般真实世界图像上产生了有希望的修复结果，但它们都表现不如我们的 $\text{NeRFLIX++}_\text{4K}$ 模型，这表明 NeRFLiX++ 在 NeRF 渲染照片上的出色修复能力。

**4 K 视频演示**：我们准备了一个视频演示，展示了我们提出的 NeRFLiX++ 方法的增强能力，可以在 https://www.youtube.com/watch?v=YiXvgQXiWII 观看。它由三部分组成。视频的前两部分强调了 TensoRF 和 Plenoxels 在生成令人满意的 1 K 新视图方面的困难，而 NeRFLiX++ 能够从这些低分辨率噪声视图中恢复超高分辨率输出。值得注意的是，NeRFLiX++ 甚至恢复了可识别的字符和更锐利的纹理，达到了 4 K 分辨率。最后一部分展示了 NeRFLiX++ 可以显著提高各种 NeRF 模型（即 TensoRF [9]、Plenoxels [17]、RegNeRF [42]、NLF [1]、DIVeR [63]、NeRF-mm [62] 等）的视觉质量。

# 9. Conclusion
我们提出了 NeRFLiX，一种通用的 NeRF 无关的修复范式，用于高质量修复神经视图合成。我们系统分析了 NeRF 渲染流程，并引入了 NeRF 风格退化的概念。为了消除 NeRF 风格的伪影，我们提出了一种新颖的 NeRF 风格退化模拟器，并构建了一个大规模的模拟数据集。通过在模拟数据集上训练最先进的深度神经网络，我们成功去除了 NeRF 伪影。此外，我们提出了一种跨视角混合器，通过聚合多视图帧来恢复 NeRF 渲染帧中缺失的细节。大量实验验证了 NeRFLiX 的有效性。
为了进一步提高 NeRFLiX 的修复能力和推理效率，我们提出了 NeRFLiX++。它通过引入更好的退化建模和更快的跨视角聚合技术改进了 NeRFLiX。NeRFLiX++ 实现了逼真的 4 K 视图合成能力，并在我们的广泛实验中展示了卓越的定量和定性性能。

