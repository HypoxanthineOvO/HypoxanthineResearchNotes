
# 1. 摘要
我们提出了一种基于深度学习的单图像超分辨率（SR）方法。该方法直接学习低分辨率图像和高分辨率图像之间的端到端映射。该映射通过一个深度卷积神经网络（CNN）表示，该网络以低分辨率图像作为输入，并输出高分辨率图像。我们进一步表明，传统的基于稀疏编码的 SR 方法也可以被视为一种深度卷积网络。但与传统方法分别处理每个组件不同，我们的方法联合优化了所有层。我们的深度 CNN 结构轻量，但展示了最先进的恢复质量，并在实际在线使用中实现了快速速度。我们探索了不同的网络结构和参数设置，以实现性能和速度之间的权衡。此外，我们扩展了网络以同时处理三个颜色通道，并展示了更好的整体重建质量。

# 2. 引言
单图像超分辨率（SR）[20]旨在从单个低分辨率图像中恢复高分辨率图像，是计算机视觉中的一个经典问题。由于对于任何给定的低分辨率像素存在多种解，因此==该问题本质上是病态的==。换句话说，这是==一个欠定的逆问题==，其解不唯一。通常通过强先验信息来约束解空间来缓解这一问题。为了学习先验，最近的最先进方法大多采用基于示例的策略[46]。这些方法要么利用同一图像的内部相似性[5], [13], [16], [19], [47]，要么从外部低分辨率和高分辨率示例对中学习映射函数[2], [4], [6], [15], [23], [25], [37], [41], [42], [47], [48], [50], [51]。基于外部示例的方法可以用于通用图像超分辨率，也可以根据提供的训练样本设计用于特定领域任务，例如人脸幻觉[30], [50]。

基于稀疏编码的方法[49], [50]是基于外部示例的 SR 方法之一。该方法在其解决方案管道中涉及几个步骤。首先，从输入图像中密集裁剪重叠的 patch 并进行预处理（例如减去均值和归一化）。然后，这些 patch 通过低分辨率字典进行编码。稀疏系数被传递到高分辨率字典中以重建高分辨率 patch。重叠的重建 patch 通过加权平均聚合以生成最终输出。该管道由大多数基于外部示例的方法共享，这些方法特别关注学习和优化字典[2], [49], [50]或构建高效的映射函数[25], [41], [42], [47]。然而，管道中的其余步骤很少在统一的优化框架中进行优化或考虑。

在本文中，我们展示了上述管道等同于一个深度卷积神经网络[27]（更多细节见第 3.2 节）。受此启发，我们考虑一个直接学习低分辨率和高分辨率图像之间端到端映射的卷积神经网络。我们的方法与现有的基于外部示例的方法有根本不同，因为我们的方法没有显式地学习字典[41], [49], [50]或流形[2], [4]来建模 patch 空间。这些通过隐藏层隐式实现。此外，patch 提取和聚合也被公式化为卷积层，因此也参与了优化。在我们的方法中，整个 SR 管道完全通过学习获得，几乎没有预处理/后处理。
![[1-01-SRCNN-001.png|373x481]]
> Fig. 1: 所提出的超分辨率卷积神经网络（SRCNN）仅通过少量训练迭代次数就超越了双三次基线，并且在适度训练的情况下优于基于稀疏编码的方法（SC）[50]。性能可能会随着更多训练迭代次数的增加而进一步提高。更多细节在第 4.4.1 节提供（使用放大因子 3 的 Set 5 数据集）。所提出的方法提供了视觉上吸引人的重建图像。

我们将提出的模型命名为超分辨率卷积神经网络（SRCNN）。提出的 SRCNN 具有几个吸引人的特性。首先，其结构设计简单，但与最先进的基于示例的方法相比，提供了更高的准确性。图 1 展示了一个示例的比较。其次，通过适度的滤波器和层数，我们的方法在实际在线使用中实现了快速速度，即使在 CPU 上也是如此。我们的方法比许多基于示例的方法更快，因为它是完全前馈的，不需要在使用时解决任何优化问题。第三，实验表明，当（i）有更大和更多样化的数据集可用时，和/或（ii）使用更大和更深的模型时，网络的恢复质量可以进一步提高。相反，更大的数据集/模型可能会对现有的基于示例的方法提出挑战。此外，提出的网络可以同时处理三个颜色通道，以实现更好的超分辨率性能。

总的来说，本研究的贡献主要体现在三个方面：
1) 我们提出了一个用于图像超分辨率的全卷积神经网络。该网络直接学习低分辨率和高分辨率图像之间的端到端映射，几乎没有预处理/后处理。
2) 我们建立了基于深度学习的 SR 方法与传统的基于稀疏编码的 SR 方法之间的关系。这种关系为网络结构的设计提供了指导。
3) 我们证明了深度学习在超分辨率这一经典计算机视觉问题中的有用性，并且可以实现良好的质量和速度。

# 3. 相关工作
#### 3.1 图像超分辨率
根据图像先验，单图像超分辨率算法可以分为四类——预测模型、基于边缘的方法、图像统计方法和基于 patch（或基于示例）的方法。这些方法在 Yang 等人的工作[46]中得到了彻底的研究和评估。其中，基于示例的方法[16], [25], [41], [47]实现了最先进的性能。

基于内部示例的方法利用自相似性属性并从输入图像生成示例 patch。它首先在 Glasner 的工作[16]中提出，随后提出了几种改进的变体[13], [45]以加速实现。基于外部示例的方法[2], [4], [6], [15], [37], [41], [48], [49], [50], [51]从外部数据集中学习低/高分辨率 patch 之间的映射。这些研究在如何学习紧凑的字典或流形空间以关联低/高分辨率 patch 以及如何在这些空间中进行表示方案方面有所不同。

在 Freeman 等人的开创性工作[14]中，字典直接表示为低/高分辨率 patch 对，并在低分辨率空间中找到输入 patch 的最近邻（NN），并使用其对应的高分辨率 patch 进行重建。Chang 等人[4]引入了流形嵌入技术作为 NN 策略的替代。在 Yang 等人的工作[49], [50]中，上述 NN 对应关系发展为更复杂的稀疏编码公式。其他映射函数如核回归[25], 简单函数[47], 随机森林[37]和锚定邻域回归[41], [42]被提出以进一步提高映射精度和速度。基于稀疏编码的方法及其几种改进[41], [42], [48]是当今最先进的 SR 方法之一。在这些方法中，patch 是优化的重点；patch 提取和聚合步骤被视为预处理/后处理并分别处理。

大多数 SR 算法[2], [4], [15], [41], [48], [49], [50], [51]专注于灰度或单通道图像超分辨率。对于彩色图像，上述方法首先将问题转换为不同的颜色空间（YCbCr 或 YUV），并且 SR 仅应用于亮度通道。也有一些工作尝试同时超分辨所有通道。例如，Kim 和 Kwon[25]以及 Dai 等人[7]将他们的模型应用于每个 RGB 通道并将它们组合以产生最终结果。然而，他们都没有分析不同通道的 SR 性能以及恢复所有三个通道的必要性。

## 3.2 卷积神经网络
卷积神经网络（CNN）可以追溯到几十年前[27]，而深度 CNN 最近因其在图像分类中的成功而爆炸性流行[18], [26]。它们也成功应用于其他计算机视觉领域，如目标检测[34], [40], [52], 人脸识别[39]和行人检测[35]。在这一进展中，几个因素至关重要：（i）在现代强大 GPU 上的高效训练实现[26]，（ii）ReLU（Rectified Linear Unit）[33]的提出，使得收敛速度更快，同时仍然保持良好的质量[26]，以及（iii）易于访问大量数据（如 ImageNet[9]）以训练更大的模型。我们的方法也受益于这些进展。

## 3.3 深度学习用于图像恢复
已有一些研究使用深度学习技术进行图像恢复。多层感知器（MLP），其所有层都是全连接的（与卷积层相对），被应用于自然图像去噪[3]和后去模糊去噪[36]。与我们的工作更密切相关的是，卷积神经网络被应用于自然图像去噪[22]和去除噪声模式（污垢/雨水）[12]。这些恢复问题或多或少是由去噪驱动的。Cui 等人[5]提出在其超分辨率管道中嵌入自编码器网络，基于内部示例方法[16]。深度模型并未专门设计为端到端解决方案，因为级联的每一层都需要独立优化自相似性搜索过程和自编码器。相反，提出的 SRCNN 优化了端到端映射。此外，SRCNN 在速度上更快。它不仅是一种定量上优越的方法，而且是一种实际有用的方法。

### 4. 卷积神经网络用于超分辨率
#### 4.1 公式化
考虑单个低分辨率图像，我们==首先使用双三次插值将其上采样到所需大小，这是我们执行的唯一预处理。==我们将插值后的图像表示为 $Y$。我们的目标是从 $Y$ 中恢复一个图像 $F(Y)$，使其尽可能接近真实的高分辨率图像 $X$。为了便于表示，我们仍然称 $Y$ 为“低分辨率”图像，尽管它与 $X$ 具有相同的大小。我们希望学习一个映射 $F$，该映射在概念上由三个操作组成：
1) **patch 提取和表示**：该操作从低分辨率图像 $Y$ 中提取（重叠的）patch，并将每个 patch 表示为高维向量。这些向量组成一组特征图，其数量等于向量的维度。
2) **非线性映射**：该操作将每个高维向量非线性映射到另一个高维向量。每个映射后的向量在概念上是高分辨率 patch 的表示。这些向量组成另一组特征图。
3) **重建**：该操作聚合上述高分辨率 patch 表示以生成最终的高分辨率图像。该图像预期与真实图像 $X$ 相似。

我们将展示所有这些操作形成一个卷积神经网络。网络的概述如图 2 所示。接下来我们详细定义每个操作。

#### 4.1.1 patch 提取和表示
在图像恢复中，一种流行的策略是密集提取 patch，然后通过一组预训练的基（如 PCA、DCT、Haar 等）表示它们。这相当于通过一组滤波器对图像进行卷积，每个滤波器都是一个基。在我们的公式中，我们将这些基的优化纳入网络的优化中。形式上，我们的第一层表示为操作 $F_1$：
$$ F_1(Y) = \max(0, W_1 * Y + B_1), $$
其中 $W_1$ 和 $B_1$ 分别表示滤波器和偏置，$*$ 表示卷积操作。这里，$W_1$ 对应于 $n_1$ 个支持大小为 $c \times f_1 \times f_1$ 的滤波器，其中 $c$ 是输入图像的通道数，$f_1$ 是滤波器的空间大小。直观上，$W_1$ 在图像上应用 $n_1$ 个卷积，每个卷积的核大小为 $c \times f_1 \times f_1$。输出由 $n_1$ 个特征图组成。$B_1$ 是一个 $n_1$ 维向量，其每个元素与一个滤波器相关联。我们在滤波器响应上应用 ReLU（$\max(0, x)$）[33]。

#### 4.1.2 非线性映射
第一层为每个 patch 提取一个 $n_1$ 维特征。在第二个操作中，我们将这些 $n_1$ 维向量中的每一个映射到一个 $n_2$ 维向量。这相当于应用 $n_2$ 个具有平凡空间支持 $1 \times 1$ 的滤波器。这种解释仅对 $1 \times 1$ 滤波器有效。但很容易推广到更大的滤波器，如 $3 \times 3$ 或 $5 \times 5$。在这种情况下，非线性映射不是对输入图像的 patch 进行，而是对特征图的 $3 \times 3$ 或 $5 \times 5$ “patch”进行。第二层的操作为：
$$ F_2(Y) = \max(0, W_2 * F_1(Y) + B_2). $$
这里 $W_2$ 包含 $n_2$ 个大小为 $n_1 \times f_2 \times f_2$ 的滤波器，$B_2$ 是 $n_2$ 维的。每个输出的 $n_2$ 维向量在概念上是将用于重建的高分辨率patch的表示。

可以添加更多的卷积层以增加非线性。但这会增加模型的复杂性（$n_2 \times f_2 \times f_2 \times n_2$ 参数用于一层），因此需要更多的训练时间。我们将在第 4.3.3 节中通过引入额外的非线性映射层来探索更深的结构。

#### 4.1.3 重建
在传统方法中，预测的重叠高分辨率 patch 通常通过平均来生成最终的完整图像。平均可以被视为对一组特征图（其中每个位置是高分辨率 patch 的“扁平化”向量形式）的预定义滤波器。受此启发，我们定义一个卷积层来生成最终的高分辨率图像：
$$ F(Y) = W_3 * F_2(Y) + B_3. $$
这里 $W_3$ 对应于 $c$ 个大小为 $n_2 \times f_3 \times f_3$ 的滤波器，$B_3$ 是一个 $c$ 维向量。
如果高分辨率 patch 的表示在图像域中（即我们可以简单地将每个表示重塑为 patch），我们期望滤波器表现得像平均滤波器；如果高分辨率 patch 的表示在其他域中（例如某些基的系数），我们期望 $W_3$ 表现得像首先将系数投影到图像域然后平均。无论哪种方式，$W_3$ 都是一组线性滤波器。

![[1-01-SRCNN-002.png|512x180]]
> Fig. 2: 给定一个低分辨率图像 $Y$，SRCNN的第一个卷积层提取一组特征图。第二层将这些特征图非线性地映射到高分辨率的补丁表示。最后一层结合空间邻域内的预测，产生最终的高分辨率图像 $F(Y)$。

有趣的是，尽管上述三个操作由不同的直觉驱动，但它们都导致与卷积层相同的形式。我们将所有三个操作放在一起，形成一个卷积神经网络（图 2）。在该模型中，所有滤波权重和偏置都被优化。尽管整体结构简洁，但我们的 SRCNN 模型是通过借鉴超分辨率[49], [50]领域的重大进展中的广泛经验精心开发的。我们将在下一节中详细说明这种关系。

#### 4.2 与基于稀疏编码方法的关系
![[1-01-SRCNN-003.png|584x208]]

> Fig. 3: 在卷积神经网络视角下稀疏编码方法的示例。

我们展示了基于稀疏编码的 SR 方法[49], [50]可以被视为卷积神经网络。图 3 展示了这一说明。
在基于稀疏编码的方法中，让我们考虑从输入图像中提取一个 $f_1 \times f_1$ 的低分辨率 patch。然后，稀疏编码求解器（如 Feature-Sign[29]）首先将 patch 投影到（低分辨率）字典上。如果字典大小为 $n_1$，这相当于在输入图像上应用 $n_1$ 个线性滤波器（$f_1 \times f_1$）（均值减法也是一个线性操作，因此可以被吸收）。这如图 3 的左侧部分所示。

稀疏编码求解器随后迭代处理这 $n_1$ 个系数。该求解器的输出是 $n_2$ 个系数，通常在稀疏编码的情况下 $n_2 = n_1$。这些 $n_2$ 个系数是高分辨率 patch 的表示。从这个意义上说，稀疏编码求解器表现为一种特殊的非线性映射操作，其空间支持为 $1 \times 1$。参见图 3 的中间部分。然而，稀疏编码求解器不是前馈的，即它是一种迭代算法。相反，我们的非线性操作是完全前馈的，并且可以高效计算。如果我们设置 $f_2 = 1$，那么我们的非线性操作可以被视为逐像素的全连接层。值得注意的是，“稀疏编码求解器”在 SRCNN 中指的是前两层，而不仅仅是第二层或激活函数（ReLU）。因此，SRCNN 中的非线性操作也通过学习过程得到了很好的优化。

上述 $n_2$ 个系数（在稀疏编码之后）随后被投影到另一个（高分辨率）字典上以生成高分辨率 patch。重叠的高分辨率 patch 随后被平均。如上所述，这相当于对 $n_2$ 个特征图进行线性卷积。如果用于重建的高分辨率 patch 的大小为 $f_3 \times f_3$，那么线性滤波器的等效空间支持大小为 $f_3 \times f_3$。参见图 3的右侧部分。

上述讨论表明，基于稀疏编码的 SR 方法可以被视为一种卷积神经网络（具有不同的非线性映射）。但并非所有操作都在基于稀疏编码的 SR 方法中进行了优化。相反，在我们的卷积神经网络中，低分辨率字典、高分辨率字典、非线性映射以及均值减法和平均都被纳入要优化的滤波器中。因此，我们的方法优化了包含所有操作的端到端映射。

上述类比还可以帮助我们设计超参数。例如，我们可以将最后一层的滤波器大小设置为小于第一层的滤波器大小，从而更多地依赖于高分辨率 patch 的中心部分（极端情况下，如果 $f_3 = 1$，我们使用中心像素而不进行平均）。我们还可以设置 $n_2 < n_1$，因为预期它会更稀疏。一个典型且基本的设置是 $f_1 = 9$, $f_2 = 1$, $f_3 = 5$, $n_1 = 64$, 和 $n_2 = 32$（我们在实验部分评估更多设置）。总的来说，高分辨率像素的估计利用了 $(9 + 5 - 1)^2 = 169$ 个像素的信息。显然，用于重建的信息比现有的基于外部示例的方法（例如使用 $(5 + 5 - 1)^2 = 81$ 个像素[15], [50]）更多。这是 SRCNN 提供优越性能的原因之一。

#### 4.3 训练
学习端到端映射函数 $F$ 需要估计网络参数 $\Theta = \{W_1, W_2, W_3, B_1, B_2, B_3\}$。这是通过最小化重建图像 $F(Y; \Theta)$ 与相应真实高分辨率图像 $X$ 之间的损失来实现的。给定一组高分辨率图像 $\{X_i\}$ 及其对应的低分辨率图像 $\{Y_i\}$，我们使用均方误差（MSE）作为损失函数：
$$ L(\Theta) = \frac{1}{n} \sum_{i=1}^n ||F(Y_i; \Theta) - X_i||^2, $$
其中 $n$ 是训练样本的数量。使用 MSE 作为损失函数有利于高 PSNR。PSNR 是用于定量评估图像恢复质量的广泛使用的指标，并且至少部分与感知质量相关。值得注意的是，卷积神经网络并不排除使用其他类型的损失函数，只要损失函数是可导的。如果在训练期间给出了更好的感知驱动指标，网络可以灵活地适应该指标。相反，这种灵活性在传统的“手工制作”方法中通常难以实现。尽管提出的模型是训练以追求高 PSNR 的，但我们仍然观察到在使用替代评估指标（例如 SSIM, MSSIM，见第 4.4.1 节）时，模型的性能令人满意。

使用标准的反向传播[28]通过随机梯度下降来最小化损失。特别是，权重矩阵更新为：
$$ \Delta_{i+1} = 0.9 \cdot \Delta_i - \eta \cdot \frac{\partial L}{\partial W_\ell^i}, \quad W_\ell^{i+1} = W_\ell^i + \Delta_{i+1}, $$
其中 $\ell \in \{1, 2, 3\}$ 和 $i$ 是层和迭代的索引，$\eta$ 是学习率，$\frac{\partial L}{\partial W_\ell^i}$ 是导数。每层的滤波器权重通过从均值为 0、标准差为 0.001 的高斯分布中随机抽取进行初始化（偏置为 0）。前两层的学习率为 $10^{-4}$，最后一层的学习率为 $10^{-5}$。我们经验发现，最后一层的学习率较小对于网络的收敛非常重要（类似于去噪情况[22]）。
在训练阶段，真实图像 $\{X_i\}$ 被准备为从训练图像中随机裁剪的 $f_{sub} \times f_{sub} \times c$ 像素的子图像。通过“子图像”，我们指的是这些样本被视为小“图像”而不是“patch”，因为“patch”是重叠的并且需要一些后处理（如平均），而“子图像”则不需要。为了合成低分辨率样本 $\{Y_i\}$，我们通过高斯核对子图像进行模糊处理，按上采样因子进行下采样，并通过双三次插值按相同因子进行上采样。
为了避免训练期间的边界效应，所有卷积层都没有填充，并且网络产生较小的输出（$(f_{sub} - f_1 - f_2 - f_3 + 3)^2 \times c$）。MSE 损失函数仅通过 $X_i$ 的中心像素与网络输出之间的差异来评估。尽管我们在训练中使用固定大小的图像，但卷积神经网络可以在测试期间应用于任意大小的图像。
我们使用 `cuda-convnet` 包[26]实现我们的模型。我们还尝试了 `Caffe` 包[24]，并观察到类似的性能。

### 5. 实验
我们首先研究了使用不同数据集对模型性能的影响。接下来，我们检查了我们的方法学习到的滤波器。然后，我们探索了网络的不同架构设计，并研究了超分辨率性能与深度、滤波器数量和滤波器大小等因素之间的关系。随后，我们在定量和定性上与最近的最先进方法进行了比较。根据[42]，在第 4.1-4.4 节中，超分辨率仅应用于亮度通道（YCbCr 颜色空间中的 Y 通道），因此第一层/最后一层的 $c = 1$，并且性能（例如 PSNR 和 SSIM）在 Y 通道上评估。最后，我们扩展了网络以处理彩色图像，并评估了不同通道上的性能。

#### 5.1 训练数据
如文献所示，深度学习通常受益于大数据训练。为了比较，我们使用了一个相对较小的训练集[41], [50]，该训练集由 91 张图像组成，以及一个由 ILSVRC 2013 ImageNet 检测训练分区中的 395,909 张图像组成的大型训练集。训练子图像的大小为 $f_{sub} = 33$。因此，91 张图像的数据集可以分解为 24,800 个子图像，这些子图像是从原始图像中以 14 的步幅提取的。而 ImageNet 即使使用 33 的步幅也提供了超过 500 万个子图像。我们使用基本的网络设置，即 $f_1 = 9$, $f_2 = 1$, $f_3 = 5$, $n_1 = 64$, 和 $n_2 = 32$。我们使用 Set 5[2]作为验证集。即使我们使用更大的 Set 14 集[51]，我们也观察到类似的趋势。上采样因子为 3。我们使用基于稀疏编码的方法[50]作为基线，其平均 PSNR 值为 31.42 dB。
![[1-01-SRCNN-004.png]]

使用不同训练集的测试收敛曲线如图 4 所示。在 ImageNet 上的训练时间与在 91 张图像数据集上的训练时间大致相同，因为反向传播的次数相同。可以观察到，在相同的反向传播次数（即 $8 \times 10^8$）下，SRCNN+ImageNet 达到了 32.52 dB，高于在 91 张图像上训练的 32.39 dB。结果积极表明，使用更大的训练集可以进一步提高 SRCNN 的性能，但大数据的效果不如在高级视觉问题[26]中显示的那样显著。这主要是因为 91 张图像已经捕捉到了自然图像的足够变异性。另一方面，我们的 SRCNN 是一个相对较小的网络（8,032 个参数），它不会对 91 张图像（24,800 个样本）过拟合。尽管如此，我们在以下实验中采用包含更多样化数据的 ImageNet 作为默认训练集。

#### 5.2 超分辨率的学习滤波器
![[1-01-SRCNN-005.png|507x197]]

![[1-01-SRCNN-006.png|545x313]]
图 5 展示了在 ImageNet 上以 3 的上采样因子训练的第一层滤波器的示例。请参阅我们发布的实现以获取上采样因子 2 和 4 的滤波器。有趣的是，每个学习到的滤波器都有其特定的功能。例如，滤波器 $g$ 和 $h$ 类似于拉普拉斯/高斯滤波器，滤波器 $a-e$ 类似于不同方向的边缘检测器，滤波器 $f$ 类似于纹理提取器。图 6 展示了不同层的特征图示例。显然，第一层的特征图包含不同的结构（例如不同方向的边缘），而第二层的特征图主要在强度上有所不同。

#### 5.3 模型与性能的权衡
基于基本的网络设置（即 $f_1 = 9$, $f_2 = 1$, $f_3 = 5$, $n_1 = 64$, 和 $n_2 = 32$），我们将逐步修改其中一些参数，以研究性能和速度之间的最佳权衡，并研究性能与参数之间的关系。

##### 5.3.1 滤波器数量
通常，如果我们增加网络宽度（即添加更多滤波器），性能会提高，但代价是运行时间。具体来说，基于我们的网络默认设置 $n_1 = 64$ 和 $n_2 = 32$，我们进行了两个实验：（i）一个是具有更大网络的 $n_1 = 128$ 和 $n_2 = 64$，（ii）另一个是具有较小网络的 $n_1 = 32$ 和 $n_2 = 16$。类似于第 4.1 节，我们还在 ImageNet 上训练这两个模型，并在 Set 5 上以 3 的上采样因子进行测试。在 $8 \times 10^8$ 次反向传播时观察到的结果如表 1 所示。显然，通过增加宽度可以实现更优越的性能。然而，如果需要快速的恢复速度，则首选较小的网络宽度，它仍然可以比基于稀疏编码的方法（31.42 dB）实现更好的性能。

##### 5.3.2 滤波器大小
在本节中，我们检查了网络对不同滤波器大小的敏感性。在之前的实验中，我们设置滤波器大小 $f_1 = 9$, $f_2 = 1$ 和 $f_3 = 5$，网络可以表示为 9-1-5。首先，为了与基于稀疏编码的方法保持一致，我们将第二层的滤波器大小固定为 $f_2 = 1$，并将其他层的滤波器大小扩大到 $f_1 = 11$ 和 $f_3 = 7$（11-1-7）。所有其他设置与第 4.1 节相同。在 Set 5 上以 3 的上采样因子进行测试的结果为 32.57 dB，略高于第 4.1 节中报告的 32.52 dB。这表明，合理较大的滤波器大小可以捕捉更丰富的结构信息，从而带来更好的结果。

然后，我们进一步检查具有较大第二层滤波器大小的网络。具体来说，我们固定滤波器大小 $f_1 = 9$, $f_3 = 5$，并将第二层的滤波器大小扩大到（i）$f_2 = 3$（9-3-5）和（ii）$f_2 = 5$（9-5-5）。图 7 中的收敛曲线显示，使用较大的滤波器大小可以显著提高性能。具体来说，9-3-5 和 9-5-5 在 Set 5 上以 $8 \times 10^8$ 次反向传播时达到的平均 PSNR 值分别为 32.66 dB 和 32.75 dB。结果表明，在映射阶段利用邻域信息是有益的。

然而，部署速度也会随着滤波器大小的增加而降低。例如，9-1-5、9-3-5 和 9-5-5 的参数数量分别为 8,032、24,416 和 57,184。9-5-5 的复杂度几乎是 9-3-5 的两倍，但性能提升是微乎其微的。因此，网络规模的选择应始终是性能和速度之间的权衡。

##### 5.3.3 层数
最近的研究[17]表明，CNN 可以通过适度增加网络深度而受益。在这里，我们尝试通过添加另一个非线性映射层来尝试更深的结构，该层具有 $n_{22} = 16$ 个大小为 $f_{22} = 1$ 的滤波器。我们进行了三个对照实验，即 9-1-1-5、9-3-1-5、9-5-1-5，它们分别在 9-1-5、9-3-5 和 9-5-5 上添加了一个额外的层。附加层的初始化方案和学习率与第二层相同。从图 13 (a)、13 (b) 和 8 (c) 中，我们可以观察到，四层网络的收敛速度比三层网络慢。然而，给定足够的训练时间，更深的网络最终会赶上并收敛到三层网络。

对于超分辨率，更深结构的有效性不如图像分类[17]中显示的那样明显。此外，我们发现更深的网络并不总是带来更好的性能。具体来说，如果我们在 9-1-5 网络上添加一个具有 $n_{22} = 32$ 个滤波器的附加层，则性能会下降，并且无法超过三层网络（见图 9 (a)）。如果我们通过添加两个具有 $n_{22} = 32$ 和 $n_{23} = 16$ 个滤波器的非线性映射层来进一步加深，则我们必须设置较小的学习率以确保收敛，但经过一周的训练后，我们仍然没有观察到更好的性能（见图 9 (a)）。我们还尝试将附加层的滤波器大小扩大到 $f_{22} = 3$，并探索两种深层结构——9-3-3-5 和 9-3-3-3。然而，从图 9 (b) 中的收敛曲线来看，这两个网络并没有显示出比 9-3-1-5 网络更好的结果。

所有这些实验表明，在这个用于超分辨率的深度模型中，“越深越好”并不成立。这可能是由于训练的困难。我们的 CNN 网络不包含池化层或全连接层，因此它对初始化参数和学习率敏感。当我们加深（例如 4 或 5 层）时，我们发现很难设置适当的学习率来保证收敛。即使它收敛了，网络也可能陷入一个糟糕的局部最小值，并且即使经过足够的训练时间，学习到的滤波器的多样性也较少。这种现象也在[16]中观察到，其中不适当的深度增加导致图像分类的精度饱和或下降。为什么“越深越好”仍然是一个开放的问题，需要进一步研究以更好地理解深度架构中的梯度和训练动态。因此，我们在以下实验中仍然采用三层网络。

#### 5.4 与最先进方法的比较
在本节中，我们展示了我们的方法与最先进方法的定量和定性结果。我们采用了性能-速度权衡良好的模型：一个三层网络，$f_1 = 9$, $f_2 = 5$, $f_3 = 5$, $n_1 = 64$, 和 $n_2 = 32$，在 ImageNet 上训练。对于每个上采样因子 $\in \{2, 3, 4\}$，我们为该因子训练一个特定的网络。

**比较**。我们将 SRCNN 与最先进的 SR 方法进行比较：
- **SC**：Yang 等人[50]的基于稀疏编码的方法
- **NE+LLE**：邻域嵌入+局部线性嵌入方法[4]
- **ANR**：锚定邻域回归方法[41]
- **A+**：调整后的锚定邻域回归方法[42]
- **KK**：Kim 和 Kwon[25]的方法，根据 Yang 等人的综合评估[46]，该方法在基于外部示例的方法中表现最佳

所有实现均来自作者提供的公开代码，所有图像均使用相同的双三次核进行下采样。

**测试集**。Set 5[2]（5 张图像）、Set 14[51]（14 张图像）和 BSD 200[32]（200 张图像）用于评估上采样因子 2、3 和 4 的性能。

**评估指标**。除了广泛使用的 PSNR 和 SSIM[43]指数外，我们还采用了另外四个评估矩阵，即信息保真度准则（IFC）[38]、噪声质量度量（NQM）[8]、加权峰值信噪比（WPSNR）和多尺度结构相似性指数（MSSSIM）[44]，这些指标在[46]中报告了与人类感知评分的高相关性。

##### 5.4.1 定量和定性评估
如表 2、表 3 和表 4 所示，提出的 SRCNN 在大多数评估矩阵中得分最高。请注意，我们的 SRCNN 结果基于 $8 \times 10^8$ 次反向传播的检查点。具体来说，对于上采样因子 3，SRCNN 在三个数据集上实现的平均 PSNR 增益分别为 0.15 dB、0.17 dB 和 0.13 dB，高于次优方法 A+[42]。当我们查看其他评估指标时，我们惊讶地发现，SC 在 IFC 和 NQM 上的得分甚至低于双三次插值。显然，SC 的结果在视觉上比双三次插值更令人愉悦。这表明这两个指标可能无法真实反映图像质量。因此，无论这两个指标如何，SRCNN 在所有方法和缩放因子中均表现最佳。

值得注意的是，SRCNN 在学习阶段的一开始就超过了双三次基线（见图 1），并且在适度的训练下，SRCNN 优于现有的最先进方法（见图 4）。然而，性能远未收敛。我们推测，给定更长的训练时间，可以获得更好的结果（见图 10）。

图 14、图 15 和图 16 展示了不同方法在 3 的上采样因子下的超分辨率结果。可以观察到，SRCNN 生成的边缘比其他方法更锐利，且在整个图像中没有明显的伪影。

此外，我们报告了另一种最近的深度学习图像超分辨率方法（DNC）[5]。由于他们使用了不同的模糊核（标准差为 0.55 的高斯滤波器），我们使用与 DNC 相同的模糊核训练了一个特定的网络（9-5-5）以进行公平的定量比较。上采样因子为 3，训练集为 91 张图像的数据集。从图 11 中的收敛曲线可以看出，我们的 SRCNN 仅用 $2.7 \times 10^7$ 次反向传播就超过了 DNC，并且给定更长的训练时间，可以获得更大的优势。这也证明了端到端学习优于 DNC，即使该模型已经是“深”的。

##### 5.4.2 运行时间
图 12 展示了几种最先进方法的运行时间比较，以及它们在 Set 14 上的恢复性能。所有基线方法均来自相应作者的 MATLAB+MEX 实现，而我们的方法是纯 C++实现的。我们使用相同的机器（Intel CPU 3.10 GHz 和 16 GB 内存）对所有算法的运行时间进行分析。请注意，我们的方法的处理时间与测试图像分辨率高度线性相关，因为所有图像都经过相同数量的卷积。我们的方法始终是性能和速度之间的权衡。为了展示这一点，我们训练了三个网络进行比较，分别是 9-1-5、9-3-5 和 9-5-5。显然，9-1-5 网络是最快的，但它仍然比次优的 A+实现了更好的性能。其他方法相比 9-1-5 网络慢了几倍甚至几个数量级。请注意，速度差距并不是主要由不同的 MATLAB/C++实现引起的；相反，其他方法需要在使用时解决复杂的优化问题（例如稀疏编码或嵌入），而我们的方法是完全前馈的。9-5-5 网络实现了最佳性能，但代价是运行时间。我们的 CNN 的测试时间速度可以通过许多方式进一步加速，例如通过近似或简化训练网络[10], [21], [31]，可能会略微降低性能。

#### 5.5 彩色通道的实验
在之前的实验中，我们遵循传统的方法来超分辨彩色图像。具体来说，我们首先将彩色图像转换为 YCbCr 空间。SR 算法仅应用于 Y 通道，而 Cb 和 Cr 通道通过双三次插值进行上采样。有趣的是，如果我们同时考虑所有三个通道，是否可以改善超分辨率性能。

我们的方法可以灵活地接受更多通道，而无需改变学习机制和网络设计。特别是，它可以通过将输入通道设置为 $c = 3$ 来同时处理三个通道。在以下实验中，我们探索了彩色图像超分辨率的不同训练策略，并随后评估了它们在不同通道上的性能。

**实现细节**。训练在 91 张图像的数据集上进行，测试在 Set 5[2]上进行。网络设置为：$c = 3$, $f_1 = 9$, $f_2 = 1$, $f_3 = 5$, $n_1 = 64$, 和 $n_2 = 32$。由于我们已经证明了 SRCNN 在不同尺度上的有效性，这里我们仅评估上采样因子 3 的性能。

**比较**。我们将我们的方法与最先进的彩色 SR 方法——KK[25]进行比较。我们还尝试了不同的学习策略进行比较：
- **仅 Y**：这是我们的基线方法，它是一个单通道（$c = 1$）网络，仅在亮度通道上训练。Cb 和 Cr 通道通过双三次插值进行上采样。
- **YCbCr**：训练在 YCbCr 空间的三个通道上进行。
- **Y 预训练**：首先，为了保证 Y 通道的性能，我们仅使用 Y 通道的 MSE 作为损失来预训练网络。然后，我们使用所有通道的 MSE 来微调参数。
- **CbCr 预训练**：我们使用 Cb 和 Cr 通道的 MSE 作为损失来预训练网络，然后在所有通道上微调参数。
- **RGB**：训练在 RGB 空间的三个通道上进行。

结果如表 5 所示，我们有以下观察结果。（i）如果我们直接在 YCbCr 通道上训练，结果甚至比双三次插值更差。由于 Y 和 Cb、Cr 通道的内在特性不同，训练陷入了一个糟糕的局部最小值。（ii）如果我们在 Y 或 Cb、Cr 通道上预训练，性能最终会提高，但仍然不如“仅 Y”在彩色图像上的表现（见表 5 的最后一列，其中 PSNR 在 RGB 颜色空间中计算）。这表明，当在统一网络中进行训练时，Cb 和 Cr 通道可能会降低 Y 通道的性能。（iii）我们观察到，对于“Y 预训练”，Cb 和 Cr 通道的 PSNR 值高于“CbCr 预训练”。原因在于 Cb、Cr 通道与 Y 通道之间的差异。视觉上，Cb 和 Cr 通道比 Y 通道更模糊，因此受下采样过程的影响较小。当我们在 Cb、Cr 通道上预训练时，只有少数滤波器被激活。然后，在微调期间，训练很快就会陷入一个糟糕的局部最小值。另一方面，如果我们在 Y 通道上预训练，更多的滤波器将被激活，并且 Cb、Cr 通道的性能将被推得更高。图 13 展示了使用“Y 预训练”策略的第一层滤波器的 Cb、Cr 通道，其模式与图 5 中显示的滤波器模式有很大不同。（iv）在 RGB 通道上训练在彩色图像上实现了最佳结果。与 YCbCr 通道不同，RGB 通道之间表现出高度的互相关性。提出的 SRCNN 能够利用通道之间的这种自然对应关系进行重建。因此，该模型在 Y 通道上实现了与“仅 Y”相当的结果，并且在 Cb、Cr 通道上比双三次插值实现了更好的结果。（v）在 KK[25]中，超分辨率分别应用于每个 RGB 通道。当我们将结果转换为 YCbCr 空间时，Y 通道的 PSNR 值与“仅 Y”相似，但 Cb 和 Cr 通道的 PSNR 值比双三次插值更差。结果表明，该算法偏向于 Y 通道。总的来说，我们在 RGB 通道上训练的方法比 KK 和单通道网络（“仅 Y”）实现了更好的性能。值得注意的是，与单通道网络相比，改进并不显著（即 0.07 dB）。这表明，Cb 和 Cr 通道在提高性能方面几乎没有帮助。

### 6. 结论
我们提出了一种新颖的深度学习方法来处理单图像超分辨率（SR）。我们展示了传统的基于稀疏编码的 SR 方法可以被重新表述为深度卷积神经网络。提出的方法 SRCNN 通过学习低分辨率和高分辨率图像之间的端到端映射，几乎没有额外的预处理/后处理。通过轻量级结构，SRCNN 实现了比最先进方法更优越的性能。我们推测，通过探索更多滤波器和不同的训练策略，可以进一步获得额外的性能。此外，提出的结构凭借其简单性和鲁棒性的优势，可以应用于其他低级视觉问题，如图像去模糊或同时进行 SR+去噪。还可以研究一个网络来处理不同的上采样因子。
