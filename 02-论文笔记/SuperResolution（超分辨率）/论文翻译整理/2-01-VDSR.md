```table-of-contents
```
# 1. Abstract
我们提出了一种高精度的单图像超分辨率（SR）方法。我们的方法使用了一个非常深的卷积网络，灵感来自于用于 ImageNet 分类的 VGG-net。我们发现增加网络深度可以显著提高精度。我们的最终模型使用了 20 个权重层。通过在深层网络结构中多次级联小滤波器，可以有效地利用大图像区域的上下文信息。然而，对于非常深的网络，训练期间的收敛速度成为一个关键问题。我们提出了一种简单但有效的训练过程。我们仅学习残差，并使用极高的学习率（比 SRCNN 高 $10^4$ 倍），通过可调节的梯度裁剪来实现。我们提出的方法在精度上优于现有方法，并且结果中的视觉改进非常明显。

# 2. Introduction
我们解决了从低分辨率（LR）图像生成高分辨率（HR）图像的问题，通常称为单图像超分辨率（SISR）。SISR 广泛应用于计算机视觉应用中，从安全和监控成像到医学成像，这些应用需要按需提供更多的图像细节。许多 SISR 方法已经在计算机视觉社区中进行了研究。早期的方法包括插值，如双三次插值和 Lanczos 重采样，以及利用统计图像先验或内部块重复的更强大方法。目前，学习方法被广泛用于建模从 LR 到 HR 块的映射。最近，随机森林和卷积神经网络（CNN）也被使用，并在精度上有显著提高。
**所遇到的现有方法的主要问题**：SRCNN 成功地将深度学习技术引入超分辨率问题，但我们发现它在三个方面存在局限性：首先，它依赖于小图像区域的上下文；其次，训练收敛速度太慢；第三，网络仅适用于单一尺度。
**我们提出的方法概述**：在这项工作中，我们提出了一种新方法来解决这些问题。我们利用分布在非常大的图像区域上的上下文信息。我们提出了一种加速训练的方法：残差学习的 CNN 和极高的学习率。我们提出了一种单模型 SR 方法，可以处理多尺度超分辨率问题。

# 3. Related Works
SRCNN 是基于深度学习的 SR 方法的代表性方法。因此，我们将其与我们的方法进行比较。

## 3.1. 用于图像超分辨率的卷积网络
SRCNN 由三层组成：块提取/表示、非线性映射和重建。分别使用了空间大小为 $9 \times 9$、$1 \times 1$ 和 $5 \times 5$ 的滤波器。在训练中，SRCNN 直接建模高分辨率图像。==我们的网络直接建模残差图像，因此可以更快地收敛==。

## 3.2. 训练
我们描述了为了找到模型的最优参数而需要最小化的目标。给定训练数据集 $\{x^{(i)}, y^{(i)}\}_{i=1}^N$，我们的目标是学习一个模型 $f$，预测值 $\hat{y} = f(x)$，其中 $\hat{y}$ 是目标 HR 图像的估计值。我们最小化训练集上的均方误差 $\frac{1}{2} ||y - f(x)||^2$。

## 3.3. 多尺度
我们设计并训练了一个单一网络来高效处理多尺度 SR 问题。我们的单一机器在给定子任务上比单一尺度专家表现更好。

# 4. 提出的方法
## 4.1. 提出的网络
我们使用了一个非常深的卷积网络来进行 SR 图像重建。网络结构如图 2 所示。我们使用了 64 个大小为 $3 \times 3 \times 64$ 的滤波器。网络以插值的低分辨率图像作为输入，并预测图像细节。
![[2-01-VDSR-001.png]]
> Figure 2: 我们的网络结构。我们反复级联一对层（卷积层和非线性层）。一个插值的低分辨率（ILR）图像通过这些层并转换成高分辨率（HR）图像。网络预测一个残差图像，ILR与残差的相加给出了所需的输出。我们为每个卷积层使用64个滤波器，并绘制了一些样本特征图以供可视化。应用修正线性单元（ReLu）后，大多数特征都是零。


## 4.2. 训练
我们描述了为了找到模型的最优参数而需要最小化的目标。给定训练数据集 $\{x^{(i)}, y^{(i)}\}_{i=1}^N$，我们的目标是学习一个模型 $f$，预测值 $\hat{y} = f(x)$，其中 $\hat{y}$ 是目标 HR 图像的估计值。我们最小化训练集上的均方误差 $\frac{1}{2} ||y - f(x)||^2$。

# 5. 理解特性
## 5.1. 越深越好
卷积神经网络通过强制相邻层神经元之间的局部连接模式来利用空间局部相关性。在这项工作中，我们使用相同大小的滤波器，$3 \times 3$，用于所有层。对于第一层，感受野的大小为 $3 \times 3$。对于接下来的层，感受野的大小在高度和宽度上都增加了 2。

## 5.2. 残差学习
我们提出了一个学习残差图像的网络结构。我们发现这种残差网络收敛得更快。在收敛时，残差网络表现出优越的性能。

## 5.3. 单一模型的多尺度
训练期间的尺度增强是装备网络以处理多尺度超分辨率机器的关键技术。我们开始进行一个有趣的实验：我们训练我们的网络使用单一尺度因子 $s_{train}$，并在另一个尺度因子 $s_{test}$ 下进行测试。

# 6. 实验结果
## 6.1. 训练和测试数据集
我们使用 291 张图像进行训练，并使用四个数据集进行基准测试：Set 5、Set 14、Urban 100 和 B 100。

## 6.2. 训练参数
我们使用深度为 20 的网络进行训练。训练使用大小为 64 的批次。动量和权重衰减参数分别设置为 0.9 和 0.0001。

## 6.3. 基准
我们遵循 Huang 等人提供的公开框架进行基准测试。该框架将双三次插值应用于图像的色彩分量，并将复杂模型应用于亮度分量。

## 6.4. 与最先进方法的比较
我们提供了定量和定性的比较。比较的方法包括 A+、RFL、SelfEx 和 SRCNN。我们的方法在这些数据集上优于所有先前的方法。

# 7. 结论
在这项工作中，我们提出了一种使用非常深网络的超分辨率方法。训练非常深的网络由于收敛速度慢而困难。我们使用残差学习和极高的学习率来快速优化非常深的网络。我们证明了我们的方法在基准图像上大大优于现有方法。我们相信我们的方法可以很容易地应用于其他图像恢复问题，如去噪和压缩伪影去除。