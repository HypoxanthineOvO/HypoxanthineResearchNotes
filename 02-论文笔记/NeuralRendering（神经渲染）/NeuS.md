# 1. Abstract
我们提出了一种新的神经表面重建方法，称为 **NeuS**，用于从 2D 图像输入中高保真地重建物体和场景。现有的神经表面重建方法，如 DVR [Niemeyer et al., 2020] 和 IDR [Yariv et al., 2020]，需要前景掩码作为监督，容易陷入局部最小值，因此在重建具有严重自遮挡或薄结构的物体时表现不佳。与此同时，最近用于新视角合成的神经方法，如 NeRF [Mildenhall et al., 2020] 及其变体，使用体渲染来生成具有优化鲁棒性的神经场景表示，即使对于高度复杂的物体也是如此。然而，从这种学习的隐式表示中提取高质量的表面是困难的，因为表示中缺乏足够的表面约束。在 **NeuS** 中，我们提出将表面表示为 **有符号距离函数 (SDF)** 的零水平集，并开发了一种新的体渲染方法来训练神经 SDF 表示。我们观察到，传统的体渲染方法会导致表面重建中的固有几何误差（即偏差），因此提出了一种在一阶近似中无偏差的新公式，从而即使在无掩码监督的情况下也能实现更准确的表面重建。在 DTU 数据集和 BlendedMVS 数据集上的实验表明，**NeuS** 在高质量表面重建方面优于现有技术，特别是对于具有复杂结构和自遮挡的物体和场景。
# 2. Introduction
从多视角图像中重建表面是计算机视觉和计算机图形学中的一个基本问题。近年来，使用神经隐式表示进行 3D 重建已成为经典重建方法的一个极具前景的替代方案 [37,8,2]，因为它具有高质量的重建能力，并且能够重建经典方法难以处理的复杂物体，如非朗伯表面和薄结构。最近的工作将表面表示为有符号距离函数 (SDF) [49,52,17,23] 或占用率 [30,31]。为了训练其神经模型，这些方法使用可微表面渲染方法将 3D 物体渲染为图像，并将其与输入图像进行比较以进行监督。例如，IDR [49] 产生了令人印象深刻的重建结果，但它无法重建具有复杂结构的物体，这些结构会导致深度突变。这种限制的原因是 IDR 中使用的表面渲染方法仅考虑每条射线的单个表面交点。因此，梯度仅存在于这个单点，这对于有效的反向传播来说过于局部化，并且当图像上存在深度突变时，优化会陷入较差的局部最小值。此外，物体掩码需要作为监督以收敛到有效表面。如图 1 (a) 顶部所示，由于孔洞引起的深度突变，神经网络会错误地将靠近前表面的点预测为蓝色，无法找到远处的蓝色表面。图 1 (b) 中的实际测试示例显示，IDR 无法正确重建具有深度突变的边缘附近的表面。
最近，NeRF [29] 及其变体探索了使用体渲染方法来学习用于新视角合成的体辐射场。这种体渲染方法沿每条射线采样多个点，并对采样点的颜色进行 $\alpha$ 合成以生成用于训练的输出像素颜色。体渲染方法的优势在于它可以处理深度突变，因为它考虑了沿射线的多个点，因此所有采样点（无论是靠近表面还是远离表面）都会产生用于反向传播的梯度信号。例如，参考图 1 (a) 底部，当发现近表面（黄色）与输入图像的颜色不一致时，体渲染方法能够训练网络找到远处的表面以生成正确的场景表示。然而，由于它旨在进行新视角合成而不是表面重建，NeRF 仅学习体密度场，从中提取高质量的表面是困难的。图 1 (b) 显示了从 NeRF 学习的密度场中提取的等值面。尽管该表面正确地处理了深度突变，但在某些平面区域中存在明显的噪声。
在这项工作中，我们提出了一种新的神经渲染方案，称为 **NeuS**，用于多视角表面重建。**NeuS** 使用 **有符号距离函数 (SDF)** 进行表面表示，并使用一种新颖的体渲染方案来学习神经 SDF 表示。具体来说，通过引入由 SDF 诱导的密度分布，我们使得体渲染方法能够应用于学习隐式 SDF 表示，从而结合了两者的优势，即使用神经 SDF 模型的准确表面表示和体渲染带来的在深度突变情况下的鲁棒网络训练。需要注意的是，简单地将标准体渲染方法应用于与 SDF 相关的密度会导致重建表面中的明显偏差（即固有几何误差）。这是一个新的重要观察结果，我们将在后面详细阐述。因此，我们提出了一种新的体渲染方案，以确保在 SDF 的一阶近似中实现无偏差的表面重建。在 DTU 数据集和 BlendedMVS 数据集上的实验表明，**NeuS** 能够重建具有严重遮挡和精细结构的复杂 3D 物体和场景，即使在没有前景掩码作为监督的情况下也是如此。它在重建质量方面优于现有的神经场景表示方法，即 IDR [49] 和 NeRF [29]。
# 3. Related Works
## 3.1 经典的多视角表面和体重建
传统的多视角 3D 重建方法大致可以分为两类：基于点和表面的重建 [2,8,9,37] 和基于体的重建 [6,3,38]。基于点和表面的重建方法通过利用图像间的光度一致性 [8] 来估计每个像素的深度图，然后将深度图融合为全局密集点云 [26, 51]。表面重建通常作为后处理步骤，使用诸如筛选泊松表面重建 [16] 等方法。重建质量严重依赖于对应匹配的质量，而对于缺乏丰富纹理的物体，匹配对应的困难通常会导致重建结果中出现严重的伪影和缺失部分。另一方面，基于体的重建方法通过从多视角图像中估计体素网格中的占用率和颜色，并评估每个体素的颜色一致性，从而规避了显式对应匹配的困难。由于可实现的体素分辨率有限，这些方法无法达到高精度。
## 3.2 神经隐式表示
一些方法通过在深度学习框架中引入归纳偏差来强制 3D 理解。这些归纳偏差可以是显式表示，如体素网格 [13,5,47]、点云 [7,25,19]、网格 [44,46,14] 和隐式表示。近年来，由神经网络编码的隐式表示引起了广泛关注，因为它是连续的并且可以实现高空间分辨率。这种表示已成功应用于形状表示 [27,28,32,4,1,10,50,33]、新视角合成 [40, 24, 15, 29, 22, 34, 35, 43, 39] 和多视角 3D 重建 [49, 30, 17, 12, 23]。我们的工作主要集中在通过经典渲染技术从 2 D 图像中学习编码 3D 空间中的几何和外观的隐式神经表示。在此范围内，相关工作可以大致基于所使用的渲染技术进行分类，即基于表面渲染的方法和基于体渲染的方法。基于表面渲染的方法 [30, 17,49,23] 假设射线的颜色仅依赖于射线与场景几何的交点的颜色，这使得梯度仅反向传播到交点附近的局部区域。因此，这些方法在重建具有严重自遮挡和深度突变的复杂物体时表现不佳。此外，它们通常需要物体掩码作为监督。相反，我们的方法在没有掩码的情况下也能很好地处理这些具有挑战性的情况。
基于体渲染的方法，如 NeRF[29]，通过沿每条射线对采样点的颜色进行 $\alpha$ 合成来渲染图像。如引言中所述，它可以处理深度突变并合成高质量图像。然而，从学习的隐式场中提取高保真表面是困难的，因为基于密度的场景表示在其等值面上缺乏足够的约束。相比之下，我们的方法通过将场景空间约束为有符号距离函数，但应用体渲染来训练这种表示，从而结合了基于表面渲染和基于体渲染的方法的优势。UNISURF [31] 是一项同时期的工作，它也通过体渲染学习隐式表面。它通过在优化过程中缩小体渲染的采样区域来提高重建质量。我们的方法与 UNISURF 的不同之处在于，UNISURF 通过占用值表示表面，而我们的方法通过 SDF 表示场景，因此可以自然地提取表面作为其零水平集，从而产生比 UNISURF 更好的重建精度，正如后面实验部分所示。
# 4. Method
给定一组 3D 物体的姿态图像 $\{I_k\}$，我们的目标是重建其表面 $S$。表面由神经隐式 SDF 的零水平集表示。为了学习神经网络的权重，我们开发了一种新的体渲染方法，从隐式 SDF 渲染图像，并最小化渲染图像与输入图像之间的差异。这种体渲染方法确保了 **NeuS** 在重建复杂结构物体时的鲁棒优化。
## 4.1 渲染过程
**场景表示**。在 **NeuS** 中，要重建的物体场景由两个函数表示：$f: \mathbb{R}^3 \rightarrow \mathbb{R}$，它将空间位置 $x \in \mathbb{R}^3$ 映射到其与物体的有符号距离，以及 $c: \mathbb{R}^3 \times S^2 \rightarrow \mathbb{R}^3$，它编码与点 $x \in \mathbb{R}^3$ 和观察方向 $v \in S^2$ 相关的颜色。这两个函数都由多层感知器 (MLP) 编码。物体的表面 $S$ 由其 SDF 的零水平集表示，即
$$
S = \{x \in \mathbb{R}^3 | f(x) = 0\}.
$$
为了将体渲染方法应用于训练 SDF 网络，我们首先引入一个概率密度函数 $\phi_s(f(x))$，称为 **S-density**，其中 $f(x), x \in \mathbb{R}^3$ 是有符号距离函数，$\phi_s(x) = s e^{-sx} / (1 + e^{-sx})^2$，通常称为 **logistic 密度分布**，是 Sigmoid 函数 $\Phi_s(x) = (1 + e^{-sx})^{-1}$ 的导数，即 $\phi_s(x) = \Phi'_s(x)$。原则上，$\phi_s(x)$ 可以是任何以 0 为中心的单峰（即钟形）密度分布；这里我们选择 logistic 密度分布，因为它在计算上方便。注意，$\phi_s(x)$ 的标准差由 $1/s$ 给出，这也是一个可训练的参数，即 $1/s$ 随着网络训练的收敛而趋近于零。
直观上，**NeuS** 的主要思想是，借助 S-density 场 $\phi_s(f(x))$，体渲染用于仅以 2 D 输入图像作为监督来训练 SDF 网络。在成功最小化基于此监督的损失函数后，网络编码的 SDF 的零水平集预计将表示一个准确重建的表面 $S$，其诱导的 S-density $\phi_s(f(x))$ 在表面附近显著高值。
**渲染**。为了学习神经 SDF 和颜色场的参数，我们建议使用体渲染方案从提出的 SDF 表示中渲染图像。给定一个像素，我们将从该像素发出的射线表示为 $\{p(t) = o + tv | t \geq 0\}$，其中 $o$ 是相机的中心，$v$ 是射线的单位方向向量。我们通过以下公式沿射线累积颜色：
$$
C(o, v) = \int_0^{+\infty} w(t) c(p(t), v) dt,
$$
其中 $C(o, v)$ 是该像素的输出颜色，$w(t)$ 是点 $p(t)$ 的权重，$c(p(t), v)$ 是沿观察方向 $v$ 的点 $p$ 处的颜色。
**权重函数的要求**。从 2 D 图像中学习准确的 SDF 表示的关键是建立输出颜色与 SDF 之间的适当连接，即基于场景的 SDF $f$ 推导出沿射线的适当权重函数 $w(t)$。下面，我们列出了对权重函数 $w(t)$ 的要求。
1. **无偏差**。给定相机射线 $p(t)$，$w(t)$ 在表面交点 $p(t^*)$ 处达到局部最大值，即 $f(p(t^*)) = 0$，也就是说，点 $p(t^*)$ 位于 SDF 的零水平集上。
2. **遮挡感知**。给定任意两个深度值 $t_0$ 和 $t_1$，满足 $f(t_0) = f(t_1)$，$w(t_0) > 0$，$w(t_1) > 0$，且 $t_0 < t_1$，则有 $w(t_0) > w(t_1)$。也就是说，当两个点具有相同的 SDF 值（因此具有相同的 SDF 诱导的 S-density 值）时，靠近视点的点对最终输出颜色的贡献应大于另一个点。
无偏差的权重函数 $w(t)$ 保证了相机射线与 SDF 零水平集的交点对该像素颜色的贡献最大。遮挡感知属性确保了当射线依次穿过多个表面时，渲染过程将正确使用离相机最近的表面的颜色来计算输出颜色。
接下来，我们将首先介绍一种直接使用标准体渲染管线的定义权重函数 $w(t)$ 的简单方法，并解释为什么它不适合重建，然后再介绍我们新颖的 $w(t)$ 构造。
**简单解决方案**。为了使权重函数具有遮挡感知性，一个自然的解决方案是基于标准体渲染公式 [29]，它通过以下公式定义权重函数：
$$
w(t) = T(t) \sigma(t),
$$
其中 $\sigma(t)$ 是经典体渲染中的 **体密度**，$T(t) = \exp(-\int_0^t \sigma(u) du)$ 表示沿射线的 **累积透射率**。为了采用标准体密度公式 [29]，这里 $\sigma(t)$ 设置为等于 S-density 值，即 $\sigma(t) = \phi_s(f(p(t)))$，权重函数 $w(t)$ 由公式 3 计算。尽管生成的权重函数具有遮挡感知性，但它是有偏差的，因为它会在重建表面中引入固有误差。如图 2 (a) 所示，权重函数 $w(t)$ 在射线到达表面点 $p(t^*)$ 之前的一个点处达到局部最大值，满足 $f(p(t^*)) = 0$。这一事实将在补充材料中证明。

**我们的解决方案**。为了介绍我们的解决方案，我们首先介绍一种直接使用归一化 S-density 作为权重的简单方法来构造无偏差的权重函数：
$$
w(t) = \frac{\phi_s(f(p(t)))}{\int_0^{+\infty} \phi_s(f(p(u))) du}.
$$
这种权重函数的构造是无偏差的，但不具有遮挡感知性。例如，如果射线穿透两个表面，SDF 函数 $f$ 将在射线上有两个零点，这会导致权重函数 $w(t)$ 上有两个峰值，生成的权重函数将平等地混合两个表面的颜色，而不考虑遮挡。

为此，我们现在将基于上述简单构造，设计一个在 SDF 的一阶近似中既具有遮挡感知性又无偏差的权重函数 $w(t)$。为了确保权重函数 $w(t)$ 的遮挡感知性，我们仍将遵循体渲染的基本框架，如公式 3 所示。然而，与上述简单解决方案中的传统处理不同，我们以一种新的方式从 S-density 定义我们的函数 $w(t)$。我们首先定义一个 **不透明密度函数** $\rho(t)$，它是标准体渲染中体密度 $\sigma$ 的对应物。然后我们通过以下公式计算新的权重函数 $w(t)$：
$$
w(t) = T(t) \rho(t), \quad \text{其中} \quad T(t) = \exp\left(-\int_0^t \rho(u) du\right).
$$

**如何推导不透明密度 $\rho$**。我们首先考虑一个简单的理想情况，即只有一个表面交点，并且表面是一个无限远离相机的平面。由于公式 4 确实满足上述假设下的要求，我们使用体渲染框架推导出与公式 4 的权重定义相对应的不透明密度 $\rho$。然后我们将这种不透明密度推广到多个表面交点的一般情况。

具体来说，在单个平面交点的简单情况下，很容易看出有符号距离函数 $f(p(t))$ 为 $-|\cos(\theta)| \cdot (t - t^*)$，其中 $f(p(t^*)) = 0$，$\theta$ 是观察方向 $v$ 与表面外法向量 $n$ 之间的夹角。由于表面假设为平面，$|\cos(\theta)|$ 是一个常数。根据公式 4，我们有：
$$
w(t) = \lim_{t^* \to +\infty} \frac{\phi_s(f(p(t)))}{\int_0^{+\infty} \phi_s(f(p(u))) du} = \lim_{t^* \to +\infty} \frac{\phi_s(f(p(t)))}{\int_0^{+\infty} \phi_s(-|\cos(\theta)|(u - t^*)) du} = \lim_{t^* \to +\infty} \frac{\phi_s(f(p(t)))}{\int_{-t^*}^{+\infty} \phi_s(-|\cos(\theta)|u^*) du^*} = \lim_{t^* \to +\infty} \frac{\phi_s(f(p(t)))}{|\cos(\theta)|^{-1} \int_{-|\cos(\theta)|t^*}^{+\infty} \phi_s(\hat{u}) d\hat{u}} = |\cos(\theta)| \phi_s(f(p(t))).
$$
回想一下，体渲染框架中的权重函数由 $w(t) = T(t) \rho(t)$ 给出，其中 $T(t) = \exp(-\int_0^t \rho(u) du)$ 表示 **累积透射率**。因此，为了推导 $\rho(t)$，我们有：
$$
T(t) \rho(t) = |\cos(\theta)| \phi_s(f(p(t))).
$$
由于 $T(t) = \exp(-\int_0^t \rho(u) du)$，很容易验证 $T(t) \rho(t) = -\frac{dT}{dt}(t)$。此外，注意 $|\cos(\theta)| \phi_s(f(p(t))) = -\frac{d\Phi_s}{dt}(f(p(t)))$。因此，我们有：
$$
\frac{dT}{dt}(t) = \frac{d\Phi_s}{dt}(f(p(t))).
$$
对等式两边积分得到：
$$
T(t) = \Phi_s(f(p(t))).
$$
取对数然后对两边求导，我们得到：
$$
\int_0^t \rho(u) du = -\ln(\Phi_s(f(p(t)))) \ \Rightarrow\  \rho(t) = \frac{\displaystyle-\frac{d\Phi_s}{dt}(f(p(t)))}{\Phi_s(f(p(t)))}.
$$

这是单平面交点理想情况下的不透明密度 $\rho(t)$ 的公式。由 $\rho(t)$ 诱导的权重函数 $w(t)$ 如图 2 (b) 所示。现在我们将不透明密度推广到一般情况，即沿射线 $p(t)$ 存在多个表面交点的情况。在这种情况下，$-\frac{d\Phi_s}{dt}(f(p(t)))$ 在 SDF 值增加的射线段上变为负值。因此，我们将其裁剪为零，以确保 $\rho$ 的值始终为非负数。这给出了以下一般情况下的不透明密度函数 $\rho(t)$：
$$
\rho(t) = \max\left(\frac{-\frac{d\Phi_s}{dt}(f(p(t)))}{\Phi_s(f(p(t)))}, 0\right).
$$
基于此公式，权重函数 $w(t)$ 可以通过标准体渲染公式 5 计算。在多个表面交点情况下的示意图如图 3 所示。

以下定理表明，在一般情况下（即包括单表面交点和多表面交点），由公式 10 和公式 5 定义的权重函数在 SDF 的一阶近似中是无偏差的。证明见补充材料。

**定理 1**
假设一个光滑表面 $S$ 由有符号距离函数 $f(x) = 0$ 的零水平集定义，且射线 $p(t) = o + tv$ 从外部进入表面 $S$，交点为 $p(t^*)$，即 $f(p(t^*)) = 0$，并且存在一个区间 $[t_l, t_r]$，使得 $t^* \in [t_l, t_r]$，且 $f(p(t))$ 在 $[t_l, t_r]$ 上单调递减。假设在此局部区间 $[t_l, t_r]$ 内，表面可以通过一个足够小的平面块进行切向近似，即 $\nabla f$ 被视为固定。那么，由公式 10 和公式 5 计算的权重函数 $w(t)$ 在 $[t_l, t_r]$ 内达到其最大值于 $t^*$。

**离散化**。为了获得不透明度和权重函数的离散对应物，我们采用与 NeRF [29] 相同的近似方案。该方案沿射线采样 $n$ 个点 $\{p_i = o + t_i v | i = 1, \dots, n, t_i < t_{i+1}\}$，以计算射线的近似像素颜色：
$$
\hat{C} = \sum_{i=1}^n T_i \alpha_i c_i,
$$
其中 $T_i$ 是离散的 **累积透射率**，定义为 $T_i = \prod_{j=1}^{i-1} (1 - \alpha_j)$，$\alpha_i$ 是离散的不透明度值，定义为：
$$
\alpha_i = 1 - \exp\left(-\int_{t_i}^{t_{i+1}} \rho(t) dt\right),
$$
可以进一步表示为：
$$
\alpha_i = \max\left(\frac{\Phi_s(f(p(t_i))) - \Phi_s(f(p(t_{i+1})))}{\Phi_s(f(p(t_i)))}, 0\right).
$$
该公式的详细推导见补充材料。
# 5. 训练
为了训练 **NeuS**，我们最小化渲染颜色与真实颜色之间的差异，而无需任何 3D 监督。除了颜色外，如果提供了掩码，我们还可以利用掩码进行监督。具体来说，我们通过随机采样一批像素及其在世界空间中的对应射线 $P = \{C_k, M_k, o_k, v_k\}$ 来优化我们的神经网络和逆标准差 $s$，其中 $C_k$ 是像素颜色，$M_k \in \{0, 1\}$ 是其可选的掩码值，每次迭代从一张图像中采样。假设点采样大小为 $n$，批次大小为 $m$。损失函数定义为：
$$
L = L_{\text{color}} + \lambda L_{\text{reg}} + \beta L_{\text{mask}}.
$$
颜色损失 $L_{\text{color}}$ 定义为：
$$
L_{\text{color}} = \frac{1}{m} \sum_k R(\hat{C}_k, C_k).
$$
与 IDR [49] 相同，我们经验性地选择 $R$ 为 L 1 损失，因为在我们观察中它对异常值具有鲁棒性且在训练中稳定。

我们在采样点上添加 Eikonal 项 [10] 来正则化 SDF $f_\theta$：
$$
L_{\text{reg}} = \frac{1}{nm} \sum_{k,i} (\|\nabla f(\hat{p}_{k,i})\|_2 - 1)^2.
$$
可选的掩码损失 $L_{\text{mask}}$ 定义为：
$$
L_{\text{mask}} = \text{BCE}(M_k, \hat{O}_k),
$$
其中 $\hat{O}_k = \sum_{i=1}^n T_{k,i} \alpha_{k,i}$ 是沿相机射线的权重之和，$\text{BCE}$ 是二元交叉熵损失。

**分层采样**。在这项工作中，我们遵循与 NeRF [29] 类似的分层采样策略。我们首先在射线上均匀采样点，然后基于粗略概率估计迭代进行重要性采样。与 NeRF 同时优化粗网络和细网络不同，我们仅维护一个网络，其中粗采样的概率基于固定标准差的 S-density $\phi_s(f(x))$ 计算，而细采样的概率基于学习的 $s$ 计算。分层采样策略的详细信息见补充材料。

# 6. 实验
## 6.1 实验设置
**数据集**。为了评估我们的方法和基线方法，我们使用了 DTU 数据集 [11] 中的 15 个场景，与 IDR [49] 使用的场景相同，涵盖了各种材料、外观和几何形状，包括对重建算法具有挑战性的情况，如非朗伯表面和薄结构。每个场景包含 49 或 64 张图像，分辨率为 $1600 \times 1200$。每个场景在有无 IDR [49] 提供的前景掩码的情况下进行了测试。我们进一步在 BlendedMVS 数据集 [48]（CC-4 许可证）的低分辨率集中测试了 7 个具有挑战性的场景。每个场景有 31 到 143 张图像，分辨率为 $768 \times 576$，掩码由 BlendedMVS 数据集提供。我们还捕获了两个薄物体的 32 张输入图像，以测试我们的方法在薄结构重建上的表现。

**基线**。(1) 最先进的表面渲染方法——IDR [49]：IDR 可以高质量地重建表面，但需要前景掩码作为监督；由于 IDR 已经展示了优于另一种基于表面渲染的方法——DVR [30] 的质量，因此我们没有与 DVR 进行比较。(2) 最先进的体渲染方法——NeRF [29]：我们使用阈值 25 从学习的密度场中提取网格。我们在补充材料中验证了这一选择。(3) 广泛使用的经典 MVS 方法——COLMAP [37]：我们使用筛选泊松表面重建 [16] 从 COLMAP 的输出点云中重建网格。(4) 同时期的工作——UNISURF [31]，它通过占用场统一了表面渲染和体渲染作为场景表示。基线方法的更多细节见补充材料。

**实现细节**。我们假设感兴趣区域位于单位球内。我们每批次采样 512 条射线，并在单个 NVIDIA RTX 2080 Ti GPU 上训练模型 300 k 次迭代，耗时 14 小时（“有掩码”设置）和 16 小时（“无掩码”设置）。对于“无掩码”设置，我们使用 NeRF++ [53] 对背景进行建模。我们的网络架构和初始化方案与 IDR [49] 类似。网络架构和训练参数的更多细节见补充材料。

## 6.2 比较
我们在有掩码监督（有掩码）和无掩码监督（无掩码）两种设置下进行了比较。我们使用与 UNISURF [31] 和 IDR [49] 相同的方式测量重建质量，即 Chamfer 距离，并在表 1 中报告了分数。结果表明，我们的方法在 DTU 数据集上的两种设置中均优于基线方法——有掩码和无掩码，以 Chamfer 距离衡量。注意，IDR 在有掩码设置下的分数以及 NeRF 和 UNISURF 在无掩码设置下的分数分别来自 IDR [49] 和 UNISURF [31]。

我们在 DTU 数据集和 BlendedMVS 数据集上进行了定性比较，分别在有掩码和无掩码设置下，如图 4 和图 5 所示。如图 4 所示，在有掩码设置下，IDR 在重建 Scan 37（DTU）中的薄金属部件时表现有限，并且由于表面渲染中的局部优化过程，无法处理 Stone（BlendedMVS）中的深度突变。NeRF 提取的网格由于体密度场对其 3D 几何形状的约束不足而存在噪声。关于无掩码设置，我们在图 5 中与 NeRF 和 COLMAP 进行了视觉比较，结果显示我们的重建表面比基线方法更具保真度。我们进一步在无掩码设置下与 UNISURF [31] 进行了比较。注意，我们使用 UNISURF 论文中报告的定性结果进行比较。我们的方法在处理具有深度突变的物体时表现更好。更多定性图像见补充材料。

## 6.3 分析
**消融研究**。为了评估权重计算的效果，我们测试了三种不同的权重构造方法，如第 3.1 节所述：(a) 简单解决方案。(b) 直接构造，如公式 4 所示。(e) 完整模型。如图 6 所示，简单解决方案的定量结果在 Chamfer 距离方面比我们的权重选择 (e) 差。这是因为它引入了表面重建的偏差。如果使用直接构造，则会出现严重的伪影。

我们还研究了 Eikonal 正则化 [10] 和几何初始化 [1] 的效果。在没有 Eikonal 正则化或几何初始化的情况下，Chamfer 距离的结果与完整模型相当。然而，它们都无法正确输出有符号距离函数。这通过 SDF 预测值与相应真实 SDF 之间的平均绝对误差 (MAE) 表明，如图 6 底部所示。MAE 是在物体的包围球内均匀采样的点上计算的。SDF 预测的定性结果见补充材料。

**薄结构**。我们进一步展示了两个具有 32 张输入图像的挑战性薄物体的结果。物体下方的丰富纹理平面用于相机校准。如图 8 所示，我们的方法能够准确重建这些薄结构，特别是在具有深度突变的边缘上。此外，与仅针对高质量薄结构重建的方法 [41,20,45,21] 不同，我们的方法可以处理包含薄结构和一般物体的场景。

# 7. 结论
我们提出了 **NeuS**，一种新的多视角表面重建方法，它将 3D 表面表示为神经 SDF，并开发了一种新的体渲染方法来训练隐式 SDF 表示。**NeuS** 产生了高质量的重建，并成功重建了具有严重遮挡和复杂结构的物体。它在定性和定量上均优于现有技术。我们方法的一个局限性是，尽管它不严重依赖于纹理特征的对应匹配，但对于无纹理物体的性能仍会下降（我们在补充材料中展示了失败案例）。此外，**NeuS** 仅有一个单一的比例参数 $s$，用于建模所有空间位置的概率分布的标准差。因此，一个有趣的未来研究主题是根据不同的局部几何特征，结合场景表示的优化，为不同空间位置建模具有不同方差的概率分布。负面社会影响：与许多其他基于学习的工作一样，我们的方法需要大量的计算资源进行网络训练，这可能对全球气候变化构成担忧。