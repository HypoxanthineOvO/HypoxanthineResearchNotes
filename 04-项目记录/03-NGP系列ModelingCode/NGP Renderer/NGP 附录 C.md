# 1. Ray Marching Step Size and Stopping

在 Synthetic NeRF 场景中，我们将其绑定到单位立方体 $[0, 1]^3$ ，我们使用等于 $Δt := \sqrt{3}/1024$ 的固定光线行进步长； $\sqrt 3$ 表示单位立方体的对角线。

在所有其他场景中，根据截距定理 ，我们将步长设置为与沿射线的距离 $t$ 成正比 $Δt := t/256$，限制在区间 $\sqrt 3/1024,s · \sqrt 3/1024$ ，其中 $s$ 是场景边界框最大轴的大小。 这种步长的选择在 $t$ 中表现出指数增长，这意味着计算成本仅随场景直径呈对数增长，而没有明显的质量损失。

最后，一旦光线的透射率降至 $10^{−4}$ 以下，我们就停止光线行进并将剩余贡献设置为零。

# 2. Occupancy Grids

为了跳过空白空间中的光线行进步骤，我们维护了 $K$ 个多尺度占用网格的级联，其中对于所有 Synthetic NeRF 场景（单个网格）， $K = 1$，对于更大的现实世界场景（最多 $5$ 个网格，取决于场景大小）， $K ∈ [1, 5]$。 每个网格的分辨率为 $128^3$ ，跨越以 $(0.5, 0.5, 0.5)$ 为中心的几何增长域 $[−2^ {k−1} +0.5, 2 ^{k−1} +0.5] ^3$ 。

每个网格单元都存储编码为单个 bit 的占用情况。 这些单元按照 Morton（z-curve）顺序排列，以便于在光线行进期间通过数字微分分析仪 (DDA) 进行 Memory-Coherent Traversal。 在光线行进期间，每当要根据上一节的步长放置样本时，如果其网格单元的 bit 是 low，则跳过该样本。

查询 $K$ 个网格中的哪一个是由样本位置 $\mathbf x$ 和步长 $Δt$ 共同决定的：在覆盖 $\mathbf x$ 的网格中，查询单元边长大于 $Δt$ 的最细的网格。

## Update the Occupancy Grids

为了在训练时不断更新占用网格，我们维护第二组具有相同布局的网格，只不过它们存储全精度浮点密度值而不是单个位。

我们通过执行以下步骤在每 $16$ 次训练迭代后更新网格。 我们

1. 将每个网格单元中的密度值衰减 $0.95$ 倍
2. 随机采样 $M$ 个候选单元，并将它们的值设置为单元内随机位置处的 NeRF 模型的当前值和密度分量的最大值，以及
3. 通过使用 $t = 1024/ \sqrt 3 · 10^{−2}$ 对每个单元的密度进行阈值化来更新占用位，这对应于将最小光线行进步骤的不透明度阈值化 $10^{− 2}$.

$M$ 个候选单元的采样策略取决于训练进度，因为占用网格在早期迭代中不存储可靠的信息。 在前 $256$ 个训练步骤中，我们均匀地采样 $M = K·128^3$ 个单元，无需重复。 对于后续的训练步骤，我们设置 $M = K·128^3 /2$，并将其分为两组。 在所有单元中均匀采样前 $M/2$ 个单元。 对剩余样本使用拒绝采样，以限制对当前占用的单元格的选择。