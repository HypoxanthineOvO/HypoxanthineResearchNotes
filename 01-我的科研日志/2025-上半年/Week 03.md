```table-of-contents
```
# 3.3（周一）
## 1. 晚上和娄老师 Meeting
- 主要内容是汇报论文写作相关的内容
- 需要准备的问题：
	- 我们还是想投好一点的期刊（TCAS-I）这种，准备写 RTL，但不知道合适不合适
	- 简单讲述一遍现在的写作思路，咨询一些有没有明显需要补的图/表
	- 需要买 Overleaf Pro
	- 后续计划：张雍治以写 RTL 为主，我和泉宇改论文和画图（我花一部分时间去下一个项目）
- 然后可能可以汇报一下下一波对浪潮项目的想法
## 2. 浪潮论文的进一步阅读和思考
### 2.1. 分析
这个论文的核心 Idea 是用 NeRF 进行背景的渲染，而其他物体则以前景的形式渲染。可以简单的认为：NeRF 用网络编码“场景”信息，而场景中的物体则由传统方案实现。这甚至需求先通过预处理提取 NeRF 中的光照信息。
这样势必导致所有的光线都需要经过整个网络的计算，可能是一种不那么高效的方法。
### 2.2. 提出我们的方法
我理解的比较合适的方法可能是用传统方法渲染的背景和 NeRF 所重建的物体进行结合。这样会有几个好处：
1. 符合“提取 3D 素材”的逻辑
2. 单个物体规模小，自由度高（不需要强行兼容大场景）
### 2.3. 系统需求设计
设想一个系统：
- 传统光栅管线
- NeRF 管线（由 Grid 编码加速，提前做好深度信息）
	- 可不可以把 NeRF 和 Deferred Shading 混合起来？似乎是可以的
	- 如果可以的话！就可以先做 Rasterization，然后做 Deferred Shading
	- 或者：把 NeRF 深度图和传统管线深度图比较一下，把被 NeRF 遮住的 Mark 成不做渲染
- 支持两个管线的任意混合
那么这就有几个需求：
1. 最好让 NeRF 本身支持重新光照（肯定有现成的方案）
2. NeRF 本身就已经变成了纯粹的 $(x, y, x,\text{d}x,\text{d}y,\text{d}z)\rightarrow (r, g, b, a)$ 计算的编码器，其采样过程完全由外界提供，编码本身可以通过 Instant NGP 实现，但采样方式有待思考（我们的 Idea 或许还能用？）
如果可行的话，可能可以实现一个 CPU+一个 GPU+多个 FPGA 的逻辑：
- CPU 做控制核心；
- GPU 负责光栅操作和找采样点；
- 找好点之后分配给 FPGA 进行计算（普通着色则放在 GPU 上计算）
这种思路的优势是什么？保留 NeRF 高保真度的特点，可能可以支持在移动设备上渲染；
尤其是实际操作的时候通常物体在图片中占比会很小（相比于单个 NeRF 大场景），可能可以提供更激进的优化支持（比如：在实时操作的时候根据距离调整 NeRF 投影的精度），这个其实很合理。所以一个有趣的优化点是如何实现在不同视觉距离下的 NeRF 渲染。
### 2.4. 设计思路总结
Step 1：Geometry 过程（Mesh 和 Grid 的混合光栅化），生成一个 Geometry Buffer（和普通 Buffer 的区别是，上面多一个 Flag 标志是算 NeRF 还是算 Shading）。包括 Shadow Map 计算。
Step 2：分配计算资源。NeRF 部分由 FPGA 算，传统部分由 GPU 算，数据都写到统一的 Memory 里。
Step 3：输出结果。
如果有自己的光栅 IP，则可以进一步进行优化。
（属于是走另一个技术路线，相当于高效率的计算？但不知道效果何如，可能更适合元宇宙吧）
## 3. 论文写作和绘图
