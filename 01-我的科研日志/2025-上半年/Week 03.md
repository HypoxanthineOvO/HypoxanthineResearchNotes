```table-of-contents
```
# 3.3（周一）
## 1. 晚上和娄老师 Meeting
- 主要内容是汇报论文写作相关的内容
- 需要准备的问题：
	- 我们还是想投好一点的期刊（TCAS-I）这种，准备写 RTL，但不知道合适不合适
	- 简单讲述一遍现在的写作思路，咨询一些有没有明显需要补的图/表
	- 需要买 Overleaf Pro
	- 后续计划：张雍治以写 RTL 为主，我和泉宇改论文和画图（我花一部分时间去下一个项目）
- 然后可能可以汇报一下下一波对浪潮项目的想法
## 2. 浪潮论文的进一步阅读和思考
### 2.1. 分析
这个论文的核心 Idea 是用 NeRF 进行背景的渲染，而其他物体则以前景的形式渲染。可以简单的认为：NeRF 用网络编码“场景”信息，而场景中的物体则由传统方案实现。这甚至需求先通过预处理提取 NeRF 中的光照信息。
这样势必导致所有的光线都需要经过整个网络的计算，可能是一种不那么高效的方法。
### 2.2. 提出我们的方法
我理解的比较合适的方法可能是用传统方法渲染的背景和 NeRF 所重建的物体进行结合。这样会有几个好处：
1. 符合“提取 3D 素材”的逻辑
2. 单个物体规模小，自由度高（不需要强行兼容大场景）
### 2.3. 系统需求设计
设想一个系统：
- 传统光栅管线
- NeRF 管线（由 Grid 编码加速，提前做好深度信息）
	- 可不可以把 NeRF 和 Deferred Shading 混合起来？似乎是可以的
	- 如果可以的话！就可以先做 Rasterization，然后做 Deferred Shading
	- 或者：把 NeRF 深度图和传统管线深度图比较一下，把被 NeRF 遮住的 Mark 成不做渲染
- 支持两个管线的任意混合
那么这就有几个需求：
1. 最好让 NeRF 本身支持重新光照（肯定有现成的方案）
2. NeRF 本身就已经变成了纯粹的 $(x, y, x,\text{d}x,\text{d}y,\text{d}z)\rightarrow (r, g, b, a)$ 计算的编码器，其采样过程完全由外界提供，编码本身可以通过 Instant NGP 实现，但采样方式有待思考（我们的 Idea 或许还能用？）
如果可行的话，可能可以实现一个 CPU+一个 GPU+多个 FPGA 的逻辑：
- CPU 做控制核心；
- GPU 负责光栅操作和找采样点；
- 找好点之后分配给 FPGA 进行计算（普通着色则放在 GPU 上计算）
这种思路的优势是什么？保留 NeRF 高保真度的特点，可能可以支持在移动设备上渲染；
尤其是实际操作的时候通常物体在图片中占比会很小（相比于单个 NeRF 大场景），可能可以提供更激进的优化支持（比如：在实时操作的时候根据距离调整 NeRF 投影的精度），这个其实很合理。所以一个有趣的优化点是如何实现在不同视觉距离下的 NeRF 渲染。
### 2.4. 设计思路总结
Step 1：Geometry 过程（Mesh 和 Grid 的混合光栅化），生成一个 Geometry Buffer（和普通 Buffer 的区别是，上面多一个 Flag 标志是算 NeRF 还是算 Shading）。包括 Shadow Map 计算。
Step 2：分配计算资源。NeRF 部分由 FPGA 算，传统部分由 GPU 算，数据都写到统一的 Memory 里。
Step 3：输出结果。
如果有自己的光栅 IP，则可以进一步进行优化。
（属于是走另一个技术路线，相当于高效率的计算？但不知道效果何如，可能更适合元宇宙吧）
## 3. 论文写作和绘图
和娄老师聊的结果基本上是认为现在的版本还非常草率，估计要经过一轮反复迭代才行。
下一波计划是配合雍治哥先写一版**比特级别的模块模拟器**，然后后续交给雍治哥。
# 3.4（周二）
## 1. 浪潮项目时间线
- C Model 的开发：预计在三月份完成，目标是把一些乱七八糟的 Mesh 和 NGP 混合出现在一张图上。
- 进一步功能拓展：查询
## 2. Relighting 论文
1. **NeRD**
2. **Relighting neural radiance fields with shadow and highlight hints**
3. **Nerfactor**: Neural factorization of shape and reflectance under an unknown illumination.
这周考虑介绍一下我想做的项目和想法好了，主打一个讲故事？
OR 讲一下基于 CNN 和 Resnet 的超分辨率（介绍一两篇）？到时候强调越往后越多越乱即可。（预告一下下周讲 Graphics 好了）
## 3. 浮点数运算转换器
昨天帮忙的时候搞的，感觉可以借此切入一波浮点数？
不过定点数似乎也有这个需求（看后面有没有人来重构一下功能好了）
唔，可以拉上雍治哥和超凡哥一起来搞。

# 3.5（周三）
## 1. Relighting 论文阅读
### NeRD: Neural Reflectance Decomposition from Image Collections
#### 1. 该篇文章的研究动机
**<span style="color:red">传统的 SVBRDF 估计技术通常需要在光照方向和相机视角受控的光照舞台设置下进行图像采集，这种方法虽然精确，但在实际应用中难以实现。</b></span> 最近的方法虽然采用了更实用的采集设置，但通常将光照限制为单一主导光源（例如相机附带的闪光灯），这显著降低了形状和材质估计的歧义，但也限制了其在实际场景中的应用。<span style="color:blue"><b>NeRD 的目标是在更灵活的采集设置下进行形状和 SVBRDF 估计，并支持在任意新光照条件下进行重光照。</b></span> 通过结合 NeRF 风格的坐标基神经表示框架，NeRD 能够分解形状、反射率和光照，并在不同光照条件下进行优化。
#### 2  . 该篇文章所提出的主要方法
NeRD 的核心方法是通过最小化输入图像的光度误差来联合优化形状、BRDF 和光照模型。<span style="color:blue"><b>与 NeRF 不同，NeRD 的体素几何表示在每个 3D 点存储 SVBRDF 参数，而不是辐射。</b></span> 每个图像通过联合优化的球面高斯光照模型进行可微分渲染。形状、BRDF 参数和光照同时优化，以最小化每个输入图像的光度渲染损失。NeRD 的架构包括两个网络：**采样网络**和**分解网络**。采样网络直接估计每个点的光照依赖颜色，而分解网络则估计视图和光照独立的 BRDF 参数和表面法线。通过可微分渲染，损失可以从输入颜色反向传播到 BRDF、法线和光照。
#### 3. 该篇文章的实验效果
实验结果表明，NeRD 在合成和真实数据集上均能实现高质量的可重光照 3D 资产。<span style="color:blue"><b>在合成数据集中，NeRD 能够准确地分解出 BRDF 参数，并在未见过的光照条件下进行重光照。</b></span> 在真实数据集中，NeRD 能够生成与验证图像接近的重光照结果，并且在不同的视角和光照条件下表现出色。与 NeRF 相比，NeRD 在处理变化光照的场景时表现更好，并且能够提取出可重光照的纹理网格，而 NeRF 则无法实现重光照。此外，NeRD 在固定光照和变化光照场景下的视图合成性能也与 NeRF 相当或更好。

### Relighting Neural Radiance Fields with Shadow and Highlight Hints
#### 1. 该篇文章的研究动机
<span style="color:red"><b>现有的方法在重光照任务中存在一些主要问题</b></span> ：传统的光照重建方法通常依赖于解析反射模型和逆向渲染技术，但这些方法在处理复杂的光传输效果时往往表现不佳，尤其是当物体的几何形状和材料属性复杂时，解耦不同的光传输组件变得非常困难。此外，现有方法通常需要大量的结构化照片（如使用光舞台拍摄），这在实际应用中非常不现实。<span style="color:blue"><b>本文提出了一种数据驱动的方法，通过引入阴影和高光提示，显著减少了所需的照片数量，同时提高了重光照的质量。</b></span>
#### 2. 该篇文章所提出的主要方法
本文的核心方法基于两个 MLP 网络：一个用于建模形状的**有符号距离函数（SDF）**，另一个用于建模光传输的**可重光照辐射网络**。具体来说：
- **密度网络**：该网络**基于 NeuS**，通过 MLP 建模物体的 SDF，并从中提取密度特征。
- **可重光照辐射网络**：该网络**接收密度网络输出的特征、当前位置、法线（从 SDF 中提取）、视角方向、光源位置以及阴影和高光提示，输出当前点的辐射值**。阴影和高光提示作为网络的输入，帮助网络更好地建模高频光传输效果。
此外，本文还提出了**阴影和高光提示**的计算方法：
- **阴影提示**：通过从视点到光源的射线进行采样，计算光源的可见性，并将其作为阴影提示输入到辐射网络中。
- **高光提示**：通过计算不同粗糙度的微表面 BRDF，生成高光提示，帮助网络更好地建模高光效果。
#### 3. 该篇文章的实验效果
本文在合成场景和真实场景上进行了广泛的实验验证，展示了该方法在不同形状、材料属性和全局光照条件下的重光照效果。实验结果表明，本文方法在仅使用 500-1000 张非结构化照片的情况下，能够生成与现有方法相当甚至更好的重光照结果。具体来说：
- **合成场景**：本文方法在包含复杂几何形状和材料属性的合成场景中表现优异，尤其是在处理阴影和高光效果时，生成的图像质量显著优于现有方法。
- **真实场景**：本文方法在真实场景中也表现出色，能够处理复杂的几何形状（如毛发）和材料属性（如半透明材料），并生成逼真的重光照结果。
此外，本文还通过消融实验验证了阴影和高光提示的有效性，结果表明，移除这些提示会导致重光照质量的显著下降。
### NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination

#### 1. 该篇文章的研究动机
**<font color='red'><b>现有的方法通常需要额外的观测数据，如已知的光照条件、扫描的几何信息，或物体在多种光照条件下的图像。这些方法要么依赖于强假设（如物体由单一材质构成），要么忽略了自阴影等复杂的光照效应。</b></font>** NeRFactor 的动机在于证明仅通过单一未知光照条件下的多视角图像，依然能够恢复出具有真实感的可重光照的 3D 模型。
#### 2. 该篇文章所提出的主要方法
**<font color='blue'><b>NeRFactor 提出了一种称为 Neural Radiance Factorization 的方法，通过从 NeRF 中提取几何信息并联合优化几何、反射率和光照，从而恢复出物体的形状和反射率。</b></font>** 具体来说，NeRFactor 通过以下步骤实现：
1. **几何初始化**：首先通过 NeRF 从输入图像中提取几何信息，并将其转化为表面表示。
2. **联合优化**：在初始化几何的基础上，联合优化表面法线、光照可见性、反照率和双向反射分布函数（BRDF）。
3. **数据驱动的 BRDF 先验**：NeRFactor 使用从真实 BRDF 测量中学习的数据驱动先验，确保恢复的反射率是合理的。
4. **光照建模**：通过显式建模光照可见性，NeRFactor 能够将阴影与反照率分离，并在任意光照条件下合成真实的软阴影或硬阴影。
#### 3. 该篇文章的实验效果
NeRFactor 在合成场景和真实场景中都取得了显著的效果，具体表现如下：
1. **高质量几何恢复**：NeRFactor 恢复的表面法线和光照可见性平滑且接近真实值，能够用于重光照任务。
2. **联合优化效果**：NeRFactor 能够同时恢复出形状、反射率和光照，生成的高质量反照率和 BRDF 能够解释观察到的图像。
3. **自由视角重光照**：NeRFactor 能够在任意光照条件下渲染新视角，并合成真实的阴影效果。
4. **材质编辑**：通过 NeRFactor 的分解结果，用户可以编辑物体的反照率和 BRDF，并在任意光照条件下重新渲染。
实验结果表明，NeRFactor 在多个任务上优于经典和基于深度学习的最先进方法，特别是在自由视角重光照和材质编辑方面表现出色。
### 总结
这几篇对我们来说都不够完美，看起来比较好的可能是 NeuS 改的那篇论文。
下一步计划是读 NeuS，然后找 NeuS 改 NGP 的方法。

## 2. 组会 Slides 准备
修改汇报计划，我简单介绍一下我们后面要做的项目好了。

## 3. 浪潮汇报准备
整理我对之前论文的理解，并简要表达我的观点和计划：
1. 我的观点：从发论文的角度，直接基于现有的算法微调硬件故事性未必足；从个人感觉角度，追求完美的高质量未必是唯一的道路
2. 我的想法：传统光栅管线和 NeRF 渲染的结合（NGP-SDF + Rasterization）
3. 计划：
	1. 先把普通 NGP 和光栅化管线连在一起，调研光栅运算调度事宜
	2. 改 NGP，支持 SDF 和重新光照，然后根据我们现有的 NGP 硬件进行调整（SDF 似乎只是渲染公式不同，其他操作一致；而重新光照根据调研，可能和光栅的很多输出是被共同需要的）
	3. 组合新的设备，发论文
## 4. ASIC Sim 开发计划
本周实现浮点数类的相互转化；后续让超凡优化一下定点数类的相互转化。
完成之后找学了 CA 的小朋友来实现浮点数类的功能。

# 3.6（周四）
## 1. Reading Group 组会

# 3.7（周五）

# 3.8（周六）

# 3.9（周日）
