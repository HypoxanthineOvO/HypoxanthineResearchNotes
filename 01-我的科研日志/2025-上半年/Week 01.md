```table-of-contents
```
# 2.17（周一）
## 1. 组会记录
- 组内现在有两个 Group 在做 Gaussian 加速器（钧然 & 浩川）
	- 浩川那边需要一些做量化的工作，把之前的代码库给了他
	- 希望这学期能有时间继续完善这个代码库
## 2. 我们的小 Group
- 这学期开始要组织论文阅读会议：
	- 分工：
		- 我：部分 Neural Rendering & 超分辨率 & 体系结构加速器
		- 张雍治：交大科研见习的论文，主要是存内计算
		- 陈泉宇：AI 加速器相关论文（从寒武纪的切入，和超凡一起）
		- 丁麒涵：Gaussian 加速器
		- 李超凡：NeRF 混合渲染，AI 加速器的体系结构（和泉宇一起）
- 计划从
- 今天要给超凡分配工作，等会 Meeting 一下
## 3. 论文阅读计划
今天的论文阅读从 SRCNN 开始。然后再根据综述的顺序阅读若干篇论文。
- 需要自己规划一下，论文翻译整理和论文笔记怎么区分。
- 个人感觉是应该克制一下全文翻译，慢慢强迫自己读原文（反正有问题随时可以问 Deepseek）

> [!note] SRCNN 也太朴素了，就是设计了一个 CNN 对图像进行优化，从现在的角度来看，当时应该是不能确定这种方法 Work，并且缺乏框架（必须手动实现全流程），但实际上 Idea 难度并不大

# 2.18（周二）
## 1. 整理 `.msgpack`
- 雍治哥整理好了 MSGPACK，今天晚上把 Profiling 数据整理好
## 2. Julia & Taichi & Jittor...?
- 泉宇提出来想看一下，但感觉比较抽象，暂时帮助不大？
- 可以考虑在下次合作项目里引入，但现在做似乎得不偿失
- 目前的计划是让他们先探索加速器和 MLSys，还是专心做比较好

## 3. 论文阅读计划
- ESPAN，应该是 SRCNN 的改进
> [!notes] 不愧是早期论文，改进的想法都很朴素，优化的核心就两个，一个是前面在 LR 图像上卷积，另一个是利用卷积搞出新的 Channels 再重新排列成

## 4. 关于组会的组织
1. 需要在今天制作好使用的 Slides 的 Marp 模板
2. 需要去对应的门上贴条（已经打印好）
3. 时间可以安排在六点到八点，搞完去打球（确信）
## 5. 目前的项目整理
1. TCSVT（已经完成大部分内容，准备投稿）（贺云翔、张雍治、陈泉宇）
2. 浙大合作项目-光栅器（贺云翔、张雍治）（可能：李超凡）
3. NeRF 和传统方案的混合渲染（和浪潮的合作项目）
4. 超分辨率芯片 IP（新内容）（贺云翔）
5. 搭建一个 DNN 加速器的软硬件栈（C-Model、RTL）：需要 MLSys + Arch，可以从简单的模型开始
6. 大语言模型的分布式部署实践（和张江实验室的合作项目）

# 2.19（周三）
## 1. 今天要和庄沄恺（23 CS） Meeting
- 对方的情况：比较了解深度学习，目标是国内外保或者本校保研、想做和深度学习相关的学习
- 得准备一些讨论的话题和问题
	- 可以沟通一下对方预计会待多久
	- 超分辨率的调研暂时看起来是一个比较合适的方向
- Meeting 结果：==先看深度学习和超分辨率的论文==。
## 2. TCSVT Profiling 遇到的问题
- Profiling 数据显示，在 Jetson Xavier NX 上，Kernel Grid 的时间占比并没有显著高于 RTX 3090 Ti，这是不符合预期的（也不符合之前的实验结果）
- 思考一下可能的情况和问题：
	- CUDA 11 对底层指令的编译进行了额外优化，减少了不必要的访存
		- 如果是这个原因，应该可以对比现在的 Hit Rate 和之前的 Hit Rate
	- 时间占比没有变长是因为有其他操作花费了更长的时间
		- 整理脚本里的具体时间数据，看绝对时间的长短情况
	- 可能是因为对 16 个 Kernel 做了平均？可能后面的 Kernel 分配到的数据和前面的 Kernel 有显著差别
		- 修改数据分析脚本，观察结果
- Hash Grid 大小选择的问题：目前看下来选择 16 或者 17
## 3. 论文的写作
- 今天主要写作 Motivation 部分的内容，需要把 Profiling 得到的具体数据填入现在的结果。
- 大部分数据都跑完了，明天整理数据，准备进入绘图阶段。

## 4 . 论文阅读计划
- 按照时间顺序来读的话今天应该读一读 EDSR 和 MDSR ？但这俩的前置工作是 VDSR
- 今天先整理所有的非深度学习工作，明天再往后读好了
# 2.20（周四）
## 1. 论文绘图小会
### 1.1. 任务分工
- 我：Ray Casting 部分的 Profiling；Ray Casting 部分的一半内容（投影优化）
- 张雍治：Profiling 的 Time Breakdown；算法优化
- 陈泉宇：NGP 执行流程、Hash Profiling、Hash 优化章节
Deadline 放在下周五之前吧，争取下周把东西给娄老师让他改改，然后我们自己就去写 RTL

## 2. Reading Group 组会
### 组会前的准备
- 需要准备一下开场的细节：
	- 先介绍一下组织这个 Reading Group 的核心宗旨
	- 然后介绍一下目前参与的同学们
	- 介绍一下各自的选题
	- 鼓励一下新同学
- 然后先我讲，第二个雍治哥，第三个 dqhgg
### 组会记录
主要记录一下雍治哥的稀疏性分享：
- 稀疏性主要就是 0 元素的个数
- 还有更细的分类，例如具体有多稀疏、非 0 元素的分布情况等等
- 根据不同的稀疏性，可以对其进行编码（可以理解为标记非 0 元素的位置）
- 不同的编码方式对应不同的硬件设计

# 2.21（周五）
## 1. 娄老师转发的邮件调研
### 1.1. 新闻内容概括
**NVIDIA 发布 RTX 50 系列 GPU 及神经渲染技术套件 RTX Kit**  
1. **核心产品**：  
   - **GeForce RTX 50 系列 GPU**：基于 Blackwell 架构，支持 AI 加速的图形渲染。  
   - **RTX Kit**：包含多个神经渲染技术 SDK，集成到游戏开发管线中，提升几何、纹理、材质和光照的逼真度，同时降低显存占用和伪影。  
2. **关键技术亮点**：  
   - **RTX 神经着色器**：将小型神经网络嵌入传统着色器，支持辐射缓存、纹理压缩、材质优化等。  
   - **神经纹理压缩**：AI 压缩技术节省 7 倍显存，保持相同画质。  
   - **神经辐射缓存（NRC）**：通过 AI 推理多次反射间接照明，提升路径追踪性能。  
   - **RTX Neural Faces**：生成式 AI 实时优化人脸渲染，减少“恐怖谷效应”。  
   - **DLSS 4 与 Reflex 2**：通过 Transformer 架构和帧预测技术提升帧率并降低 75%延迟。  
   - **ACE 自主游戏角色**：生成式 AI 驱动的 NPC，支持自然语言交互和动态决策。  
3. **开发者支持**：  
   - 与微软合作支持 DirectX 的 Cooperative Vector，利用 Tensor Core 加速神经着色器。  
   - 提供 SDK 工具链（如 Streamline、RTX 角色渲染 SDK），简化 AI 技术集成。  
### 1.2. 与神经辐射场（NeRF）渲染的差异分析
| **维度**         | **NVIDIA RTX 神经渲染**                     | **NeRF（神经辐射场）**                  |
|------------------|--------------------------------------------|-----------------------------------------|
| **核心目标**     | **实时渲染优化**：提升游戏性能与画质，降低资源消耗。 | **高保真静态场景重建**：从多视图 2 D 图像生成 3 D 辐射场模型。 |
| **技术方法**     | 将 AI 与传统渲染管线（如着色器、光线追踪）结合，局部优化（如纹理压缩、间接照明推理）。 | 全场景的连续体素表示，通过 MLP 网络建模光线传播和颜色/密度分布。 |
| **实时性**       | 支持实时渲染（≥60 FPS），依赖硬件加速（Tensor Core）。 | 通常离线训练与推理，实时性差（需预计算或简化模型）。 |
| **应用场景**     | 动态游戏场景、复杂几何体、角色渲染。                | 静态场景重建（如数字孪生、文化遗产保护）。 |
| **资源消耗**     | 显存优化（如神经纹理压缩）、降低光线追踪计算负载。      | 高计算资源需求（训练时间长，显存占用大）。 |
| **光照模型**     | 基于物理的渲染（PBR）+ AI 辅助优化（如 NRC 加速间接光照）。 | 隐式全局光照建模，无需显式光照方程。 |
| **输入数据**     | 传统几何数据（三角形网格）+ AI 增强（如生成式面部细节）。 | 多视角 2 D 图像或点云数据。 |

### 1.3. 关键差异总结
1. **目标导向**：  
   - **RTX 神经渲染**：以“性能优化”为核心，通过 AI 增强传统渲染管线，解决实时游戏的效率与画质矛盾。  
   - **NeRF**：以“场景重建”为核心，追求静态场景的高保真表示，牺牲实时性换取精度。  
2. **技术融合程度**：  
   - **RTX 神经渲染**：AI 与传统图形技术（如着色器、光线追踪）深度耦合，保留显式几何结构。  
   - **NeRF**：完全依赖神经网络隐式表示场景，脱离传统渲染管线。  
3. **适用领域**：  
   - **RTX 神经渲染**：更适合动态、交互式应用（如 3 A 游戏、虚拟角色）。  
   - **NeRF**：更适合静态场景的高质量重建（如影视特效、AR/VR 环境建模）。  
## 2. 论文阅读
今天要读的论文应该是 VDSR。

## 3. TCSVT
### 3.1. Ray Casting 的统计

### 3.2. 论文写作

# 2.22（周六）


# 2.23（周日）
