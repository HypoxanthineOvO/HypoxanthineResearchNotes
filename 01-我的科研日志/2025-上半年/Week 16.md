# 6.2（周一）
## 1. ML PJ
在 NGP 上实现了评估，多跑一些数据，要准备开始写报告了
# 6.3（周二）
## 1. ML PJ
### 实现 MAT
看看到底多久会收敛（？）主要是还有学习率的影响
### 数据分析
- NGP 一直在调整 color MLP，其他的模块在摆大烂（）
- 感觉可以考虑根据这个结果去验证，哈希表一下就学好了
- 下一步除了用他的 MAT 之外也可以考虑根据这个结论去调整不同模块的学习率
### 后续论文主要框架设计
1. 前两章做推导和证明
2. 介绍他的策略
3. 介绍神经渲染任务，解读为编码和存储任务
4. 提出我们对神经渲染的想法，然后探索对密度编码和对颜色编码的难度，以及容量之类的信息（？）
5. 然后放对比实验，主要包括：
	1. 不同配置下 NGP 的效果、Lambda Max 等的分布
	2. 加上 MAT 策略之后的优化比例
	3. NGP vs NeRF，对比神经网络 x Hash Table

## 2. 毕设视频和海报
毕设的简单介绍：
1. 我的个人信息
2. 毕设介绍：神经渲染的重要性（30 字），系统的分析了其中的瓶颈（50 字），提出了针对最大瓶颈的方案并做了硬件实现，实现了几百倍的能效比和实时渲染效果

视频部分：
- 10 s 个人介绍
- 40 s：NeRF 的兴起，诸多方法，我们进行了系统的对比
- 20 s：图表的展示，主要通过图表去分析瓶颈
- 30 s：Ray Casting 的动画和投影的动画讲解
- 30 s：Hash Encoding 的动画
- 20 s：结果展示
- 30 s：用 FPGA 抠图+视频展示我们的渲染效果

# 6.4（周三）

# 6.5（周四）

# 6.6（周五）

